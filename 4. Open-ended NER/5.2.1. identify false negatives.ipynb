{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "9f41c990",
            "metadata": {},
            "source": [
                "Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b513c9fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Libraries\n",
                "import numpy as np\n",
                "import sys\n",
                "import os\n",
                "import json\n",
                "from pathlib import Path\n",
                "import re\n",
                "import litellm \n",
                "from pydantic import BaseModel\n",
                "import pandas as pd\n",
                "\n",
                "# add path to the dataset entities\n",
                "sys.path.append(os.path.abspath(\"../0. Helpers\"))\n",
                "sys.path.append(os.path.abspath(\"../2. Data Processing/_dataset_entities\"))\n",
                "\n",
                "from datasets import load_dataset, load_from_disk\n",
                "from datasetProcessing import Entity, recursive_fix\n",
                "from reflection_helpers import get_token_context_include, get_token_context_exclude, get_entity_context"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00b6fea7",
            "metadata": {},
            "source": [
                "Settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a228dad",
            "metadata": {},
            "outputs": [],
            "source": [
                "# potential_tokens_folder = \"paper\"\n",
                "# prob_threshold = 0.95\n",
                "\n",
                "potential_tokens_folder = \"adapted\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a38a8d5d",
            "metadata": {},
            "source": [
                "Topic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6ec88d30",
            "metadata": {},
            "outputs": [],
            "source": [
                "all_configs = {\n",
                "    \"ai\": 10,\n",
                "    \"literature\": 10,\n",
                "    \"music\": 10,\n",
                "    \"politics\": 20,\n",
                "    \"science\": 20,\n",
                "    \"multinerd_en\": 20,\n",
                "    \"multinerd_pt\": 20,\n",
                "    \"ener\": 20,\n",
                "    \"lener\": 20,\n",
                "    \"neuralshift\": 20\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fbf57d1b",
            "metadata": {},
            "source": [
                "Process functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "176ffb54",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_token(topic, token):\n",
                "\n",
                "    # Search for examples where token is inside\n",
                "    classification_path = Path(f\"classification/{topic}/train/data\")\n",
                "\n",
                "    positive_examples = []\n",
                "\n",
                "    # classification files\n",
                "    for file in classification_path.glob(\"*.json\"):\n",
                "\n",
                "        with open(file, mode='r', encoding=\"utf-8\") as f:\n",
                "            content = f.read()\n",
                "            \n",
                "        content = re.sub(r',\\s*$', '', content)\n",
                "        data = json.loads(content)\n",
                "\n",
                "        true_entities = data[\"true_entities\"]\n",
                "        entity_tokens = data[\"classification\"][\"entity\"]\n",
                "        \n",
                "        if token in entity_tokens:\n",
                "            for entity in true_entities:\n",
                "                if token in entity[\"span\"]:\n",
                "                    context = get_entity_context(data[\"sentence\"], entity[\"span\"], context_length = 4)\n",
                "                    \n",
                "                    if context:\n",
                "                        demonstration = {\n",
                "                            \"sentence\": f\"...{' '.join(context)}...\",\n",
                "                            \"entity\": entity[\"span\"]\n",
                "                        }\n",
                "                        positive_examples.append(demonstration)\n",
                "\n",
                "                    else:\n",
                "                        print(topic)\n",
                "                        print(file.name)\n",
                "                        print(token)\n",
                "                        raise ValueError(\"No context found\")\n",
                "\n",
                "\n",
                "    token_json = {\n",
                "        \"token\": token,\n",
                "        \"positive_examples\": positive_examples,\n",
                "    }\n",
                "    \n",
                "    return token_json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6cc67165",
            "metadata": {},
            "outputs": [],
            "source": [
                "def identify_false_negatives(tokens, llm_entities, probs_dict):\n",
                "\n",
                "    false_negative_tokens = []\n",
                "\n",
                "    # check tokens that are likely entity \n",
                "    for idx, token in enumerate(tokens):\n",
                "\n",
                "        if token in probs_dict:\n",
                "\n",
                "            # paper vs adapted!\n",
                "            if potential_tokens_folder == \"adapted\":\n",
                "                high_prob = probs_dict[token][\"prob_e\"] == 1\n",
                "            elif potential_tokens_folder == \"paper\" and prob_threshold:\n",
                "                high_prob = probs_dict[token][\"prob_e\"] >= prob_threshold\n",
                "            else:\n",
                "                raise ValueError(\"Invalid potential_tokens_folder\")\n",
                "\n",
                "            if high_prob:\n",
                "\n",
                "                # check if token is not inside a predicted entity\n",
                "                if all(token.lower() not in e[\"span\"].lower() for e in llm_entities) and token not in false_negative_tokens:\n",
                "\n",
                "                    context = get_token_context_exclude(tokens, idx)\n",
                "\n",
                "                    # check if tokens on context are not part of predicted entity\n",
                "                    context_not_inside_entity = []\n",
                "\n",
                "                    for t in context:\n",
                "\n",
                "                        not_inside_entity = all(t.lower() not in e[\"span\"].lower() for e in llm_entities)\n",
                "                        context_not_inside_entity.append(not_inside_entity)\n",
                "\n",
                "                    # if ALL tokens in context are NOT inside entity\n",
                "                    if all(context_not_inside_entity):\n",
                "                        false_negative_tokens.append(token)\n",
                "\n",
                "    return false_negative_tokens"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7c8a8170",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_instance(topic, file_path, probs_dict):\n",
                "    \n",
                "    with open(file_path, mode='r', encoding=\"utf-8\") as f:\n",
                "        content = f.read()\n",
                "\n",
                "    if not content.strip():\n",
                "        print(f\"ðŸ—‘ï¸ Empty file detected: {file_path}\")\n",
                "        return None\n",
                "\n",
                "    # Fix JSON extra comma\n",
                "    content = re.sub(r',\\s*$', '', content)\n",
                "    data = json.loads(content)\n",
                "\n",
                "    # Apply encoding fix\n",
                "    data = recursive_fix(data)  \n",
                "\n",
                "    # extract entities\n",
                "    tokens = data[\"tokens\"]\n",
                "    # true_entities = data.get(\"true_entities\", [])\n",
                "    llm_entities = data[\"entities\"]\n",
                "    sentence = data[\"sentence\"]\n",
                "\n",
                "    false_negative_tokens = identify_false_negatives(tokens, llm_entities, probs_dict)\n",
                "    instance_tokens_info = []\n",
                "\n",
                "    if false_negative_tokens:\n",
                "        \n",
                "        print(f\"Found {len(false_negative_tokens)} false negative tokens in {file_path}\")\n",
                "        print(\"Sentence: \", sentence)\n",
                "        print(false_negative_tokens)\n",
                "        print(\"\\n---\\n\")\n",
                "\n",
                "        for token in false_negative_tokens:\n",
                "            token_with_examples = process_token(topic, token)\n",
                "\n",
                "            # only keep tokens with more than 1 positive example\n",
                "            if len(token_with_examples[\"positive_examples\"]) > 1:\n",
                "                instance_tokens_info.append(token_with_examples)\n",
                "\n",
                "        if instance_tokens_info:\n",
                "            instance_output_json = {\n",
                "                \"sentence\": sentence,\n",
                "                \"false_negative_tokens\": instance_tokens_info\n",
                "            }\n",
                "\n",
                "            # save token to a file\n",
                "            output_path = f\"error_reflection/false_negatives/{topic}/{potential_tokens_folder}/{Path(file_path).stem}.json\"\n",
                "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
                "                f.write(json.dumps(instance_output_json, ensure_ascii=False, indent=4))\n",
                "\n",
                "    return instance_tokens_info"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fef698ca",
            "metadata": {},
            "source": [
                "Run for all configs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1be5f4a",
            "metadata": {},
            "outputs": [],
            "source": [
                "false_negative_summary = {}\n",
                "\n",
                "for topic, n in all_configs.items():\n",
                "\n",
                "    print(f\"Processing topic: {topic} with top {n} demos\")\n",
                "\n",
                "    best_results_folder = f\"results/demo_type/{topic}/in_context_top{n}\"\n",
                "\n",
                "    # ensure folder exists\n",
                "    os.makedirs(f\"error_reflection/false_negatives/{topic}/{potential_tokens_folder}\", exist_ok=True)\n",
                "\n",
                "    # load probs dict\n",
                "    probs_path = f\"classification/{topic}/train/_probs.json\"\n",
                "\n",
                "    # read file\n",
                "    with open(probs_path, \"r\", encoding=\"utf-8\") as f:\n",
                "        probs_dict = json.load(f)\n",
                "\n",
                "    # Process all instances in the folder\n",
                "    instances = 0\n",
                "    instances_with_false_neg = 0\n",
                "\n",
                "    total_false_neg_tokens = 0\n",
                "\n",
                "    for file_path in Path(best_results_folder).glob(\"*.json\"):\n",
                "        instances += 1\n",
                "\n",
                "        false_neg_tokens = process_instance(topic, file_path, probs_dict)\n",
                "        \n",
                "        if false_neg_tokens:\n",
                "            instances_with_false_neg += 1\n",
                "            total_false_neg_tokens += len(false_neg_tokens)\n",
                "\n",
                "    false_negative_summary[topic] = {\n",
                "        \"instances\": instances,\n",
                "        \"instances_with_false_neg\": instances_with_false_neg,\n",
                "        \"instances_with_false_neg_percent\": instances_with_false_neg / instances * 100,\n",
                "        \"total_false_neg_tokens\": total_false_neg_tokens,\n",
                "    }\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "112727cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "for topic, summary in false_negative_summary.items():\n",
                "    print(f\"Topic: {topic}\")\n",
                "    print(f\"Instances with false negatives: {summary['instances_with_false_neg']} ({summary['instances_with_false_neg_percent']:.1f}%)\")\n",
                "    print(f\"Total false negative tokens: {summary['total_false_neg_tokens']}\")\n",
                "\n",
                "    print(\"\\n---\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
