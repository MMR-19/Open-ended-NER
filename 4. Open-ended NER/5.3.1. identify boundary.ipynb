{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "9f41c990",
            "metadata": {},
            "source": [
                "Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b513c9fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Libraries\n",
                "import numpy as np\n",
                "import sys\n",
                "import os\n",
                "import json\n",
                "from pathlib import Path\n",
                "import re\n",
                "import litellm \n",
                "from pydantic import BaseModel\n",
                "import pandas as pd\n",
                "\n",
                "# add path to the dataset entities\n",
                "sys.path.append(os.path.abspath(\"../0. Helpers\"))\n",
                "sys.path.append(os.path.abspath(\"../2. Data Processing/_dataset_entities\"))\n",
                "\n",
                "from datasetProcessing import Entity, recursive_fix\n",
                "from reflection_helpers import get_token_context_include, get_token_context_exclude, get_entity_context, get_entity_inner_boundary"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00b6fea7",
            "metadata": {},
            "source": [
                "Settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a228dad",
            "metadata": {},
            "outputs": [],
            "source": [
                "# potential_tokens_folder = \"paper\"\n",
                "# prob_threshold = 0.95\n",
                "\n",
                "potential_tokens_folder = \"adapted\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a38a8d5d",
            "metadata": {},
            "source": [
                "Topic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6ec88d30",
            "metadata": {},
            "outputs": [],
            "source": [
                "all_configs = {\n",
                "    \"ai\": 10,\n",
                "    \"literature\": 10,\n",
                "    \"music\": 10,\n",
                "    \"politics\": 20,\n",
                "    \"science\": 20,\n",
                "    \"multinerd_en\": 20,\n",
                "    \"multinerd_pt\": 20,\n",
                "    \"ener\": 20,\n",
                "    \"lener\": 20,\n",
                "    \"neuralshift\": 20\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fbf57d1b",
            "metadata": {},
            "source": [
                "Process functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "176ffb54",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_token(topic, token, boundary, entity_str):\n",
                "\n",
                "    # Search for examples where token is inside\n",
                "    classification_path = Path(f\"classification/{topic}/train/data\")\n",
                "\n",
                "    examples = []\n",
                "\n",
                "    # classification files\n",
                "    for file in classification_path.glob(\"*.json\"):\n",
                "\n",
                "        with open(file, mode='r', encoding=\"utf-8\") as f:\n",
                "            content = f.read()\n",
                "            \n",
                "        content = re.sub(r',\\s*$', '', content)\n",
                "        data = json.loads(content)\n",
                "\n",
                "        true_entities = data[\"true_entities\"]\n",
                "        entity_tokens = data[\"classification\"][\"entity\"]\n",
                "        context_tokens = data[\"classification\"][\"context\"]\n",
                "\n",
                "        # if boundary is inside, check context tokens\n",
                "        if boundary == \"inside\":\n",
                "            if token in context_tokens:\n",
                "                for entity in true_entities:\n",
                "                    # get context\n",
                "                    context = get_entity_context(data[\"sentence\"], entity[\"span\"], context_length = 4)\n",
                "                    if context and token in context:\n",
                "                        \n",
                "                        demonstration = {\n",
                "                            \"sentence\": f\"...{' '.join(context)}...\",\n",
                "                            \"entity\": entity[\"span\"]\n",
                "                        }\n",
                "                        examples.append(demonstration)\n",
                "\n",
                "        # if boundary is outside, check entity tokens\n",
                "        elif boundary == \"outside\":\n",
                "            if token in entity_tokens:\n",
                "                for entity in true_entities:\n",
                "                    # check if token is in this entity span\n",
                "                    if token in entity[\"span\"]:\n",
                "                        context = get_entity_context(data[\"sentence\"], entity[\"span\"], context_length = 4)\n",
                "                        if context:\n",
                "                            demonstration = {\n",
                "                                \"sentence\": f\"...{' '.join(context)}...\",\n",
                "                                \"entity\": entity[\"span\"]\n",
                "                            }\n",
                "                            examples.append(demonstration)\n",
                "\n",
                "        else:\n",
                "             raise ValueError(\"Boundary must be either 'inside' or 'outside'\")\n",
                "\n",
                "    token_json = {\n",
                "        \"boundary\": boundary,\n",
                "        \"token\": token,\n",
                "        \"entity_str\": entity_str,\n",
                "        \"examples\": examples,\n",
                "    }\n",
                "    \n",
                "    return token_json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6cc67165",
            "metadata": {},
            "outputs": [],
            "source": [
                "def identify_boundary(sentence, llm_entities, probs_dict):\n",
                "\n",
                "    outer_tokens = []\n",
                "    inner_tokens = []\n",
                "\n",
                "    for entity in llm_entities:\n",
                "\n",
                "        entity_str = f\"{{'span': '{entity['span']}', 'entity': '{entity['entity']}'}}\"\n",
                "\n",
                "        # process outer context\n",
                "        outer_context = get_entity_context(sentence, entity[\"span\"], context_length = 1, include_entity = False)\n",
                "\n",
                "        if not outer_context:\n",
                "            print()\n",
                "            print(\"âŒ-------------\")\n",
                "            print(\"sentence: \",   sentence)\n",
                "            print(\"entity:   \", entity[\"span\"])\n",
                "            print(\"âŒ-------------\")\n",
                "            print()\n",
                "            continue\n",
                "            \n",
                "\n",
                "        # check tokens that are likely entity \n",
                "        for token in outer_context:\n",
                "            if token in probs_dict:\n",
                "\n",
                "                # paper vs adapted!\n",
                "                if potential_tokens_folder == \"adapted\":\n",
                "                    high_prob = probs_dict[token][\"prob_e\"] == 1\n",
                "                elif potential_tokens_folder == \"paper\" and prob_threshold:\n",
                "                    high_prob = probs_dict[token][\"prob_e\"] >= prob_threshold\n",
                "                else:\n",
                "                    raise ValueError(\"Invalid potential_tokens_folder\")\n",
                "                \n",
                "                if high_prob:\n",
                "                    \n",
                "                    # check if token is not inside a predicted entity\n",
                "                    if all(token.lower() not in e[\"span\"].lower() for e in llm_entities) and token not in outer_tokens:\n",
                "                        outer_tokens.append((token, entity_str))\n",
                "\n",
                "        # process inner context\n",
                "        inner_context = get_entity_inner_boundary(entity[\"span\"], context_length = 1)\n",
                "\n",
                "        # check tokens that are likely context \n",
                "        for token in inner_context:\n",
                "            if token in probs_dict and probs_dict[token][\"prob_c\"] == 1:\n",
                "                inner_tokens.append((token, entity_str))\n",
                "\n",
                "    return inner_tokens, outer_tokens\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7c8a8170",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_instance(topic, file_path, probs_dict):\n",
                "    \n",
                "    with open(file_path, mode='r', encoding=\"utf-8\") as f:\n",
                "        content = f.read()\n",
                "\n",
                "    if not content.strip():\n",
                "        print(f\"ðŸ—‘ï¸ Empty file detected: {file_path}\")\n",
                "        return None\n",
                "\n",
                "    # Fix JSON extra comma\n",
                "    content = re.sub(r',\\s*$', '', content)\n",
                "    data = json.loads(content)\n",
                "\n",
                "    # Apply encoding fix\n",
                "    data = recursive_fix(data)  \n",
                "\n",
                "    # extract entities\n",
                "    # true_entities = data.get(\"true_entities\", [])\n",
                "    llm_entities = data[\"entities\"]\n",
                "    sentence = data[\"sentence\"]\n",
                "\n",
                "    inside_boundary, outside_boundary = identify_boundary(sentence, llm_entities, probs_dict)\n",
                "    inside_boundary_info, outside_boundary_info = [], []\n",
                "\n",
                "    if inside_boundary or outside_boundary:\n",
                "        print(f\"Found {len(inside_boundary)} inside boundary tokens and {len(outside_boundary)} outside boundary tokens in {file_path}\")\n",
                "        print(\"Sentence: \", sentence)\n",
                "        print(inside_boundary)\n",
                "        print(outside_boundary)\n",
                "        print(\"\\n---\\n\")\n",
                "\n",
                "        for token, entity_str in inside_boundary:\n",
                "            token_with_examples = process_token(topic, token, \"inside\", entity_str)\n",
                "\n",
                "            # only keep tokens with more than 1 positive example\n",
                "            if len(token_with_examples[\"examples\"]) > 1:\n",
                "                inside_boundary_info.append(token_with_examples)\n",
                "\n",
                "        for token, entity_str in outside_boundary:\n",
                "            token_with_examples = process_token(topic, token, \"outside\", entity_str)\n",
                "\n",
                "            # only keep tokens with more than 1 positive example\n",
                "            if len(token_with_examples[\"examples\"]) > 1:\n",
                "                outside_boundary_info.append(token_with_examples)\n",
                "\n",
                "        if inside_boundary_info or outside_boundary_info:\n",
                "            instance_output_json = {\n",
                "                \"sentence\": sentence,\n",
                "                \"inside_boundary_tokens\": inside_boundary_info,\n",
                "                \"outside_boundary_tokens\": outside_boundary_info\n",
                "            }\n",
                "\n",
                "            # save token to a file\n",
                "            output_path = f\"error_reflection/boundary/{topic}/{potential_tokens_folder}/{Path(file_path).stem}.json\"\n",
                "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
                "                f.write(json.dumps(instance_output_json, ensure_ascii=False, indent=4))\n",
                "\n",
                "    return inside_boundary_info, outside_boundary_info"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fef698ca",
            "metadata": {},
            "source": [
                "Run for all configs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1be5f4a",
            "metadata": {},
            "outputs": [],
            "source": [
                "boundary_summary = {}\n",
                "\n",
                "for topic, n in all_configs.items():\n",
                "\n",
                "    print(f\"Processing topic: {topic} with top {n} demos\")\n",
                "\n",
                "    best_results_folder = f\"results/demo_type/{topic}/in_context_top{n}\"\n",
                "\n",
                "    # ensure folder exists\n",
                "    os.makedirs(f\"error_reflection/boundary/{topic}/{potential_tokens_folder}\", exist_ok=True)\n",
                "\n",
                "    # load probs dict\n",
                "    probs_path = f\"classification/{topic}/train/_probs.json\"\n",
                "\n",
                "    # read file\n",
                "    with open(probs_path, \"r\", encoding=\"utf-8\") as f:\n",
                "        probs_dict = json.load(f)\n",
                "\n",
                "    # Process all instances in the folder\n",
                "    instances = 0\n",
                "    instances_with_inside_boundary = 0\n",
                "    instances_with_outside_boundary = 0\n",
                "\n",
                "    total_inside_boundary_tokens = 0\n",
                "    total_outside_boundary_tokens = 0\n",
                "\n",
                "    for file_path in Path(best_results_folder).glob(\"*.json\"):\n",
                "        instances += 1\n",
                "\n",
                "        inside_boundary_tokens, outside_boundary_tokens = process_instance(topic, file_path, probs_dict)\n",
                "        \n",
                "        if inside_boundary_tokens:\n",
                "            instances_with_inside_boundary += 1\n",
                "            total_inside_boundary_tokens += len(inside_boundary_tokens)\n",
                "\n",
                "        if outside_boundary_tokens:\n",
                "            instances_with_outside_boundary += 1\n",
                "            total_outside_boundary_tokens += len(outside_boundary_tokens)\n",
                "\n",
                "    boundary_summary[topic] = {\n",
                "        \"instances\": instances,\n",
                "        \"instances_with_inside_boundary\": instances_with_inside_boundary,\n",
                "        \"instances_with_inside_boundary_percent\": instances_with_inside_boundary / instances * 100,\n",
                "        \"total_inside_boundary_tokens\": total_inside_boundary_tokens,\n",
                "        \"instances_with_outside_boundary\": instances_with_outside_boundary,\n",
                "        \"instances_with_outside_boundary_percent\": instances_with_outside_boundary / instances * 100,\n",
                "        \"total_outside_boundary_tokens\": total_outside_boundary_tokens,\n",
                "    }\n",
                "    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "112727cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "for topic, summary in boundary_summary.items():\n",
                "    print(f\"Topic: {topic}\")\n",
                "    print(f\"Instances with inside boundary: {summary['instances_with_inside_boundary']} ({summary['instances_with_inside_boundary_percent']:.1f}%)\")\n",
                "    print(f\"Total inside boundary tokens: {summary['total_inside_boundary_tokens']}\")\n",
                "\n",
                "    print(f\"Instances with outside boundary: {summary['instances_with_outside_boundary']} ({summary['instances_with_outside_boundary_percent']:.1f}%)\")\n",
                "    print(f\"Total outside boundary tokens: {summary['total_outside_boundary_tokens']}\")\n",
                "\n",
                "    print(\"\\n---\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
