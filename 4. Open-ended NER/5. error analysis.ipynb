{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "409a19bc",
            "metadata": {},
            "source": [
                "Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c2f91dd6",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Libraries\n",
                "import numpy as np\n",
                "import sys\n",
                "import os\n",
                "import json\n",
                "from pathlib import Path\n",
                "import re\n",
                "\n",
                "# add path to the dataset entities\n",
                "sys.path.append(os.path.abspath(\"../0. Helpers\"))\n",
                "sys.path.append(os.path.abspath(\"../2. Data Processing/_dataset_entities\"))\n",
                "\n",
                "from datasetProcessing import Entity, recursive_fix\n",
                "from performance import Prediction, Performance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6943b645",
            "metadata": {},
            "outputs": [],
            "source": [
                "class ErrorClass:\n",
                "    def __init__(self, tp, type, misalign, fp, fn):\n",
                "        self.tp = tp\n",
                "        self.type = type\n",
                "        self.misalign = misalign\n",
                "        self.fp = fp\n",
                "        self.fn = fn\n",
                "\n",
                "\n",
                "def spans_overlap(span1: str, span2: str) -> bool:\n",
                "    return span1 in span2 or span2 in span1\n",
                "\n",
                "def spans_match(span1: str, span2: str) -> bool:\n",
                "    return span1 == span2\n",
                "\n",
                "def classify_error(true_entities: list[dict], pred_entities: list[dict]):\n",
                "    n_tp = 0\n",
                "    n_type = 0\n",
                "    n_misalign = 0\n",
                "    n_coverage_fp = 0\n",
                "    n_coverage_fn = 0\n",
                "\n",
                "    matched_true = set()\n",
                "    matched_pred = set()\n",
                "\n",
                "    for i, t in enumerate(true_entities):\n",
                "        for j, p in enumerate(pred_entities):\n",
                "            \n",
                "            if spans_match(t[\"span\"], p[\"span\"]):\n",
                "                matched_true.add(i); matched_pred.add(j)\n",
                "                if t[\"entity\"] != p[\"entity\"]:\n",
                "                    n_type += 1  # same span, wrong type\n",
                "                else:\n",
                "                    n_tp += 1  # correct prediction\n",
                "                break\n",
                "\n",
                "            elif spans_overlap(t[\"span\"], p[\"span\"]) and t[\"entity\"] == p[\"entity\"]:\n",
                "                matched_true.add(i); matched_pred.add(j)\n",
                "                # overlapping spans, same type\n",
                "                n_misalign += 1\n",
                "                break\n",
                "        else:\n",
                "            n_coverage_fn += 1  # gold entity not matched by any prediction\n",
                "\n",
                "    # remaining predictions are false positives\n",
                "    for j, p in enumerate(pred_entities):\n",
                "        if j not in matched_pred:\n",
                "            n_coverage_fp += 1\n",
                "\n",
                "    return ErrorClass(n_tp, n_type, n_misalign, n_coverage_fp, n_coverage_fn)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c09b66e4",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_instance(file_path):\n",
                "    \n",
                "    try:\n",
                "        with open(file_path, mode='r', encoding=\"utf-8\") as f:\n",
                "            content = f.read()\n",
                "\n",
                "        if not content.strip():\n",
                "            print(f\"üóëÔ∏è Empty file detected: {file_path}\")\n",
                "            # file_path.unlink()\n",
                "            return None\n",
                "\n",
                "        # Fix JSON extra comma\n",
                "        content = re.sub(r',\\s*$', '', content)\n",
                "        data = json.loads(content)\n",
                "\n",
                "        # Apply encoding fix\n",
                "        data = recursive_fix(data)\n",
                "\n",
                "        # extract entities  \n",
                "        true_entities = data.get(\"true_entities\", [])\n",
                "        llm_entities = data.get(\"entities\", [])\n",
                "\n",
                "        # remove duplicates from llm entities\n",
                "        predicted_entities = []\n",
                "        for entity in llm_entities:\n",
                "\n",
                "            for added_entity in predicted_entities:\n",
                "                if entity[\"span\"].strip().lower() == added_entity[\"span\"].strip().lower() and entity[\"entity\"].strip().lower() == added_entity[\"entity\"].strip().lower():\n",
                "                    break\n",
                "            else:\n",
                "                predicted_entities.append(entity)\n",
                "\n",
                "        return classify_error(true_entities, predicted_entities)\n",
                "\n",
                "    except Exception as e:\n",
                "        print(f\"‚ùå Error reading {file_path}: {e}\")\n",
                "        # file_path.unlink()\n",
                "        return None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eae6a56e",
            "metadata": {},
            "source": [
                "Evaluate each model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6f97c797",
            "metadata": {},
            "outputs": [],
            "source": [
                "folder_prefix = \"results/demo_type\"\n",
                "folder_suffix = \"in_context_top\"\n",
                "\n",
                "all_configs = {\n",
                "    \"ai\": 10,\n",
                "    \"literature\": 10,\n",
                "    \"music\": 10,\n",
                "    \"politics\": 20,\n",
                "    \"science\": 20,\n",
                "    \"multinerd_en\": 20,\n",
                "    \"multinerd_pt\": 20,\n",
                "    \"ener\": 20,\n",
                "    \"lener\": 20,\n",
                "    \"neuralshift\": 20\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a4b3739a",
            "metadata": {},
            "outputs": [],
            "source": [
                "for topic, n in all_configs.items():\n",
                "    \n",
                "    print(f\"Processing topic: {topic}\")\n",
                "    topic_path = Path(f\"{folder_prefix}/{topic}/{folder_suffix}{n}\")\n",
                "    print(topic_path)\n",
                "\n",
                "    if not topic_path.exists():\n",
                "        print(f\"‚ùå Topic folder {topic} does not exist.\")\n",
                "        continue\n",
                "\n",
                "    # Process all instances in the folder\n",
                "    dataset_performance = []\n",
                "    for file_path in topic_path.glob(\"*.json\"):\n",
                "        result = process_instance(file_path)\n",
                "        dataset_performance.append(result)\n",
                "\n",
                "    # Filter out None results\n",
                "    dataset_performance = [instance for instance in dataset_performance if instance is not None]\n",
                "    if not dataset_performance:\n",
                "        print(f\"‚ö†Ô∏è No valid instances found in {topic_path.name}. Skipping...\")\n",
                "        continue\n",
                "    else:\n",
                "        print(f\"‚úÖ Processed {len(dataset_performance)} valid instances in {topic_path.name}.\")\n",
                "\n",
                "    # compute individual performance metrics\n",
                "    metrics_dict = {\n",
                "        \"total_samples\": len(dataset_performance),\n",
                "        \"type_errors\": sum(instance.type for instance in dataset_performance),\n",
                "        \"misalign_errors\": sum(instance.misalign for instance in dataset_performance),\n",
                "        \"coverage_fn\": sum(instance.fn for instance in dataset_performance),\n",
                "        \"coverage_fp\": sum(instance.fp for instance in dataset_performance),\n",
                "        \"true_positives\": sum(instance.tp for instance in dataset_performance),\n",
                "    }\n",
                "\n",
                "    print(\"topic:\", topic)\n",
                "    print(\"metrics:\", metrics_dict)\n",
                "    print(\"\\n\\n\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
