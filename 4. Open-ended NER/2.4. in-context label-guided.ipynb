{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "7f6e5c22",
            "metadata": {},
            "source": [
                "Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f05205be",
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import json\n",
                "from pathlib import Path\n",
                "\n",
                "from concurrent.futures import ThreadPoolExecutor\n",
                "\n",
                "# add path \n",
                "sys.path.append(os.path.abspath(\"../0. Helpers\"))\n",
                "sys.path.append(os.path.abspath(\"../2. Data Processing/_dataset_entities\"))\n",
                "\n",
                "from datasets import load_dataset, load_from_disk\n",
                "from datasetProcessing import tokens_to_sentence, tokens_to_entities, join_datasets, recursive_fix"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a4e8f7e2",
            "metadata": {},
            "source": [
                "Process whole dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e1e4d692",
            "metadata": {},
            "outputs": [],
            "source": [
                "topic = \"music\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e49ca6be",
            "metadata": {},
            "outputs": [],
            "source": [
                "if topic == \"lener\":\n",
                "    from entities_leNER import entity_names, entity_names_parsed\n",
                "    dataset = load_from_disk(\"...\")\n",
                "    lang = \"portuguese\"\n",
                "\n",
                "elif topic == \"neuralshift\":\n",
                "    from entities_neuralshift import entity_names, entity_names_parsed\n",
                "    dataset = load_from_disk(\"...\")\n",
                "    lang = \"portuguese\"\n",
                "\n",
                "elif topic == \"ener\":\n",
                "    from entities_eNER import entity_names, entity_names_parsed\n",
                "    dataset = load_from_disk(\"...\")\n",
                "    lang = \"english\"\n",
                "\n",
                "elif topic == \"multinerd_en\":\n",
                "    from entities_multinerd_en import entity_names, entity_names_parsed\n",
                "    dataset = load_from_disk(\"...\")\n",
                "    lang = \"english\"\n",
                "\n",
                "elif topic == \"multinerd_pt\":\n",
                "    from entities_multinerd_pt import entity_names, entity_names_parsed\n",
                "    dataset = load_from_disk(\"...\")\n",
                "    lang = \"portuguese\"\n",
                "\n",
                "else:\n",
                "    from entities_crossNER import entity_names, entity_names_parsed\n",
                "    dataset = load_dataset(\"...\")\n",
                "    lang = \"english\"\n",
                "\n",
                "# train_data\n",
                "train_data = dataset[\"train\"]\n",
                "test_data = dataset[\"test\"]\n",
                "\n",
                "# get the entity names\n",
                "start_of_entity_indices = [i for i in range(len(entity_names)) if (entity_names[i].startswith(\"B-\") or entity_names[i].startswith(\"U-\"))]\n",
                "entity_index_to_name = {i: entity_names[i].split(\"-\")[1] for i in range(len(entity_names)) if entity_names[i] != \"O\"}\n",
                "entity_index_to_name[0] = \"O\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bde95d80",
            "metadata": {},
            "source": [
                "Read probs for topic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d60c7f52",
            "metadata": {},
            "outputs": [],
            "source": [
                "lambda_token = 1.0\n",
                "lambda_embed = 1.0\n",
                "\n",
                "w_e = 1.0\n",
                "w_c = 1.0\n",
                "w_o = 0.01"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9573489b",
            "metadata": {},
            "outputs": [],
            "source": [
                "probs_path = f\"classification/{topic}/train/_probs.json\"\n",
                "\n",
                "# read file\n",
                "with open(probs_path, \"r\", encoding=\"utf-8\") as f:\n",
                "    probs = json.load(f)\n",
                "\n",
                "vocabulary = list(probs.keys())\n",
                "\n",
                "print(probs)\n",
                "print(vocabulary)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "42449b3b",
            "metadata": {},
            "source": [
                "Run for all test instances"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8d69c11b",
            "metadata": {},
            "outputs": [],
            "source": [
                "test_len = len(dataset[\"test\"])\n",
                "train_len = len(dataset[\"train\"])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c9d71302",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Loop test\n",
                "for test_index in range(test_len):\n",
                "\n",
                "    test_instance = dataset[\"test\"][test_index]\n",
                "    test_sentence = tokens_to_sentence(test_instance['tokens'])\n",
                "\n",
                "    # Create folder\n",
                "    os.makedirs(f\"in_context/{topic}/test/data/{test_index}\", exist_ok=True)\n",
                "\n",
                "    # For each test instance, loop through all train instances\n",
                "    for train_index in range(train_len):\n",
                "\n",
                "        print(f\"\\rtest {test_index+1}/{test_len} | train {train_index+1}/{train_len}\", end='', flush=True)\n",
                "\n",
                "        similarity_test_train_path = f\"in_context/{topic}/test/data/{test_index}/{train_index}.json\"\n",
                "\n",
                "        # read file if exists\n",
                "        if os.path.exists(similarity_test_train_path):\n",
                "            with open(similarity_test_train_path, \"r\", encoding=\"utf-8\") as f:\n",
                "                existing_data = json.loads(f.read())\n",
                "                s_label_qwen = existing_data.get(\"s_label_qwen\", None)\n",
                "        \n",
                "        if not s_label_qwen:\n",
                "            db_file_path = f\"classification/{topic}/train/data/{train_index}.json\"\n",
                "            db_file = json.load(open(db_file_path, \"r\", encoding=\"utf-8\"))\n",
                "\n",
                "            # Get similarity from folder\n",
                "            with open(similarity_test_train_path, \"r\", encoding=\"utf-8\") as f:\n",
                "                train_similarity_data = json.load(f)\n",
                "                s_embed_qwen = train_similarity_data.get('s_embed_qwen', None)\n",
                "            \n",
                "            # token similarity\n",
                "            s_token = 0\n",
                "            for token in test_instance['tokens']:\n",
                "                if token in db_file['tokens']:\n",
                "                    if token not in vocabulary:\n",
                "                        s_token += 1\n",
                "                    else:\n",
                "                        s_token += probs[token]['prob_e'] * w_e + probs[token]['prob_c'] * w_c + probs[token]['prob_o'] * w_o\n",
                "\n",
                "            # final similarity\n",
                "            s_label_qwen = lambda_token * s_token + lambda_embed * s_embed_qwen if s_embed_qwen else None\n",
                "\n",
                "            # Save to json file\n",
                "            train_similarity_data[\"s_token\"] = s_token\n",
                "            train_similarity_data[\"s_label_qwen\"] = s_label_qwen\n",
                "\n",
                "            with open(similarity_test_train_path, \"w\", encoding=\"utf-8\") as f:\n",
                "                f.write(json.dumps(train_similarity_data, ensure_ascii=False, indent=4))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1168893a",
            "metadata": {},
            "source": [
                "Get top n demos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7a2fbc33",
            "metadata": {},
            "outputs": [],
            "source": [
                "# all_n = [10, 20]\n",
                "all_n = [5]\n",
                "\n",
                "# Ensure result dir exists\n",
                "for n in all_n:\n",
                "    os.makedirs(f\"in_context/{topic}/test/label{str(n)}/qwen\", exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ce127d6d",
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_similarity_file(similarity_path):\n",
                "    with open(similarity_path, \"r\", encoding=\"utf-8\") as f:\n",
                "        return json.load(f)\n",
                "    \n",
                "for test_index, instance in enumerate(dataset[\"test\"]):\n",
                "    print(f\"\\rProcessing test instance {test_index+1}/{len(dataset['test'])}\", end='', flush=True)\n",
                "\n",
                "    # Check if output files already exist\n",
                "    output_file = f\"in_context/{topic}/test/label{str(n)}/qwen/{test_index}.txt\"\n",
                "    if os.path.exists(output_file):\n",
                "        print(f\" >>> Results for sentence #{test_index+1} already exist. Skipping...\")\n",
                "        continue\n",
                "\n",
                "    # Get all train similarities and compute top n\n",
                "    # similarity_files = []\n",
                "\n",
                "    # for train_index in range(train_len):\n",
                "    #     similarity_file = load_similarity_file(f\"in_context/{topic}/test/data/{test_index}/{train_index}.json\")\n",
                "    #     similarity_files.append(similarity_file)\n",
                "\n",
                "    # Build all file paths first (faster than string interpolation in loop)\n",
                "    test_dir = f\"in_context/{topic}/test/data/{test_index}\"\n",
                "    similarity_paths = [f\"{test_dir}/{train_index}.json\" for train_index in range(train_len)]\n",
                "\n",
                "    # Parallel load all similarity files\n",
                "    with ThreadPoolExecutor(max_workers=8) as executor:\n",
                "        similarity_files = list(executor.map(load_similarity_file, similarity_paths))\n",
                "\n",
                "    # Sort by final similarity (qwen)\n",
                "    similarity_files.sort(key=lambda x: x['s_label_qwen'], reverse=True)\n",
                "    \n",
                "    for n in all_n:\n",
                "        top_n_qwen = similarity_files[:n]\n",
                "\n",
                "        qwen_demo_txt = \"\"\n",
                "        for i, similarity_file in enumerate(top_n_qwen):\n",
                "            qwen_demo_txt += f\"Example #{i+1}: {similarity_file['sentence']}\\n\"\n",
                "            qwen_demo_txt += f\"Expected output: 'entities: {similarity_file['true_entities']}'\\n\\n\"\n",
                "\n",
                "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
                "            f.write(qwen_demo_txt)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
