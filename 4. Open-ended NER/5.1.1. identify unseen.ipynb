{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "9f41c990",
            "metadata": {},
            "source": [
                "Libraries"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "b513c9fe",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Libraries\n",
                "import numpy as np\n",
                "import sys\n",
                "import os\n",
                "import json\n",
                "from pathlib import Path\n",
                "import re\n",
                "import litellm \n",
                "from pydantic import BaseModel\n",
                "import pandas as pd\n",
                "\n",
                "# add path to the dataset entities\n",
                "sys.path.append(os.path.abspath(\"../0. Helpers\"))\n",
                "sys.path.append(os.path.abspath(\"../2. Data Processing/_dataset_entities\"))\n",
                "\n",
                "from datasetProcessing import Entity, recursive_fix\n",
                "from reflection_helpers import get_token_context_include, get_token_context_exclude, get_entity_context"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00b6fea7",
            "metadata": {},
            "source": [
                "Settings"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0a228dad",
            "metadata": {},
            "outputs": [],
            "source": [
                "# potential_tokens_folder = \"paper\"\n",
                "# prob_threshold = 0.95\n",
                "\n",
                "potential_tokens_folder = \"adapted\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a38a8d5d",
            "metadata": {},
            "source": [
                "Topic"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6ec88d30",
            "metadata": {},
            "outputs": [],
            "source": [
                "all_configs = {\n",
                "    \"ai\": 10,\n",
                "    \"literature\": 10,\n",
                "    \"music\": 10,\n",
                "    \"politics\": 20,\n",
                "    \"science\": 20,\n",
                "    \"multinerd_en\": 20,\n",
                "    \"multinerd_pt\": 20,\n",
                "    \"ener\": 20,\n",
                "    \"lener\": 20,\n",
                "    \"neuralshift\": 20\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fbf57d1b",
            "metadata": {},
            "source": [
                "Process functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "176ffb54",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_token(topic, token_with_context):\n",
                "\n",
                "    # Search for examples where token is inside\n",
                "    classification_path = Path(f\"classification/{topic}/train/data\")\n",
                "\n",
                "    positive_examples = []\n",
                "\n",
                "    # classification files\n",
                "    for file in classification_path.glob(\"*.json\"):\n",
                "\n",
                "        with open(file, mode='r', encoding=\"utf-8\") as f:\n",
                "            content = f.read()\n",
                "            \n",
                "        content = re.sub(r',\\s*$', '', content)\n",
                "        data = json.loads(content)\n",
                "\n",
                "        true_entities = data[\"true_entities\"]\n",
                "        entity_tokens = data[\"classification\"][\"entity\"]\n",
                "        context_tokens = data[\"classification\"][\"context\"]\n",
                "        \n",
                "        # check for context\n",
                "        for token in token_with_context[\"context_high_prob\"]:\n",
                "\n",
                "            # candidate if in entity or context tokens\n",
                "            if token in entity_tokens or token in context_tokens:\n",
                "\n",
                "                for entity in true_entities:\n",
                "                    if token in entity[\"span\"]:\n",
                "                        context = get_entity_context(data[\"sentence\"], entity[\"span\"], context_length = 4)\n",
                "                        \n",
                "                        if context:\n",
                "                            demonstration = {\n",
                "                                \"sentence\": f\"...{' '.join(context)}...\",\n",
                "                                \"entity\": entity[\"span\"]\n",
                "                            }\n",
                "                        else:\n",
                "                            print(topic)\n",
                "                            print(file.name)\n",
                "                            print(token)\n",
                "                            raise ValueError(\"No context found\")\n",
                "\n",
                "                        positive_examples.append(demonstration)\n",
                "\n",
                "    token_json = {\n",
                "        \"token\": token,\n",
                "        \"positive_examples\": positive_examples,\n",
                "    }\n",
                "    \n",
                "    return token_json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6cc67165",
            "metadata": {},
            "outputs": [],
            "source": [
                "def identify_unseen(tokens, llm_entities, probs_dict):\n",
                "\n",
                "    unseen_tokens = []\n",
                "    keys_lower = {key.lower() for key in probs_dict.keys()}\n",
                "\n",
                "    # check for unseen tokens\n",
                "    for idx, token in enumerate(tokens):\n",
                "        if token.lower() not in keys_lower:\n",
                "\n",
                "            # check if token is not inside a predicted entity\n",
                "            if all(token.lower() not in e[\"span\"].lower() for e in llm_entities) and token not in unseen_tokens:\n",
                "\n",
                "                context = get_token_context_exclude(tokens, idx)\n",
                "            \n",
                "                # check if tokens on context have high probability of being entity/context\n",
                "                context_high_prob = []\n",
                "                context_not_inside_entity = []\n",
                "\n",
                "                for t in context:\n",
                "\n",
                "                    # paper vs adapted!\n",
                "                    if potential_tokens_folder == \"adapted\":\n",
                "                        high_prob = t in probs_dict and (probs_dict[t][\"prob_e\"] == 1 or probs_dict[t][\"prob_c\"] == 1)\n",
                "                    elif potential_tokens_folder == \"paper\" and prob_threshold:\n",
                "                        high_prob = t in probs_dict and (probs_dict[t][\"prob_e\"] >= prob_threshold or probs_dict[t][\"prob_c\"] >= prob_threshold)\n",
                "                    else:\n",
                "                        raise ValueError(\"Invalid potential_tokens_folder\")\n",
                "                    \n",
                "                    not_inside_entity = all(t.lower() not in e[\"span\"].lower() for e in llm_entities)\n",
                "    \n",
                "                    context_high_prob.append(high_prob)\n",
                "                    context_not_inside_entity.append(not_inside_entity)\n",
                "\n",
                "                # if ANY token in context has high prob and ALL are not inside entity\n",
                "                if any(context_high_prob) and all(context_not_inside_entity):\n",
                "\n",
                "                    unseen_tokens.append({\n",
                "                        \"token\": token,\n",
                "                        \"context\": context,\n",
                "                        \"context_high_prob\": [s for s, f in zip(context, context_high_prob) if f]\n",
                "                    })\n",
                "\n",
                "    return unseen_tokens"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7c8a8170",
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_instance(topic, file_path, probs_dict):\n",
                "    \n",
                "    with open(file_path, mode='r', encoding=\"utf-8\") as f:\n",
                "        content = f.read()\n",
                "\n",
                "    if not content.strip():\n",
                "        print(f\"ðŸ—‘ï¸ Empty file detected: {file_path}\")\n",
                "        return None\n",
                "\n",
                "    # Fix JSON extra comma\n",
                "    content = re.sub(r',\\s*$', '', content)\n",
                "    data = json.loads(content)\n",
                "\n",
                "    # Apply encoding fix\n",
                "    data = recursive_fix(data)  \n",
                "\n",
                "    # extract entities\n",
                "    tokens = data[\"tokens\"]\n",
                "    # true_entities = data.get(\"true_entities\", [])\n",
                "    llm_entities = data[\"entities\"]\n",
                "    sentence = data[\"sentence\"]\n",
                "\n",
                "    unseen_tokens = identify_unseen(tokens, llm_entities, probs_dict)\n",
                "    instance_tokens_info = []\n",
                "\n",
                "    if unseen_tokens:\n",
                "        \n",
                "        print(f\"Found {len(unseen_tokens)} unseen tokens in {file_path}\")\n",
                "        print(\"Sentence: \", sentence)\n",
                "        print(unseen_tokens)\n",
                "        print(\"\\n---\\n\")\n",
                "\n",
                "        for token_with_context in unseen_tokens:\n",
                "            token_with_examples = process_token(topic, token_with_context)\n",
                "\n",
                "            # only keep tokens with more than 1 positive example\n",
                "            if len(token_with_examples[\"positive_examples\"]) > 1:\n",
                "                instance_tokens_info.append(token_with_examples)\n",
                "\n",
                "        if instance_tokens_info:\n",
                "            instance_output_json = {\n",
                "                \"sentence\": sentence,\n",
                "                \"unseen_tokens\": instance_tokens_info\n",
                "            }\n",
                "\n",
                "            # save token to a file\n",
                "            output_path = f\"error_reflection/unseen/{topic}/{potential_tokens_folder}/{Path(file_path).stem}.json\"\n",
                "            with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
                "                f.write(json.dumps(instance_output_json, ensure_ascii=False, indent=4))\n",
                "\n",
                "    return instance_tokens_info"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fef698ca",
            "metadata": {},
            "source": [
                "Run for all configs"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d1be5f4a",
            "metadata": {},
            "outputs": [],
            "source": [
                "unseen_summary = {}\n",
                "\n",
                "for topic, n in all_configs.items():\n",
                "\n",
                "    print(f\"Processing topic: {topic} with top {n} demos\")\n",
                "\n",
                "    best_results_folder = f\"results/demo_type/{topic}/in_context_top{n}\"\n",
                "\n",
                "    # ensure folder exists\n",
                "    os.makedirs(f\"error_reflection/unseen/{topic}/{potential_tokens_folder}\", exist_ok=True)\n",
                "\n",
                "    # load probs dict\n",
                "    probs_path = f\"classification/{topic}/train/_probs.json\"\n",
                "\n",
                "    # read file\n",
                "    with open(probs_path, \"r\", encoding=\"utf-8\") as f:\n",
                "        probs_dict = json.load(f)\n",
                "\n",
                "    # Process all instances in the folder\n",
                "    instances = 0\n",
                "    instances_with_unseen = 0\n",
                "\n",
                "    total_unseen_tokens = 0\n",
                "\n",
                "    for file_path in Path(best_results_folder).glob(\"*.json\"):\n",
                "        instances += 1\n",
                "\n",
                "        unseen_tokens = process_instance(topic, file_path, probs_dict)\n",
                "        \n",
                "        if unseen_tokens:\n",
                "            instances_with_unseen += 1\n",
                "            total_unseen_tokens += len(unseen_tokens)\n",
                "\n",
                "    unseen_summary[topic] = {\n",
                "        \"instances\": instances,\n",
                "        \"instances_with_unseen\": instances_with_unseen,\n",
                "        \"instances_with_unseen_percent\": instances_with_unseen / instances * 100,\n",
                "        \"total_unseen_tokens\": total_unseen_tokens,\n",
                "    }   "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "112727cc",
            "metadata": {},
            "outputs": [],
            "source": [
                "for topic, summary in unseen_summary.items():\n",
                "    print(f\"Topic: {topic}\")\n",
                "    print(f\"Instances with unseen: {summary['instances_with_unseen']} ({summary['instances_with_unseen_percent']:.1f}%)\")\n",
                "    print(f\"Total unseen tokens: {summary['total_unseen_tokens']}\")\n",
                "\n",
                "    print(\"\\n---\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.11"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
