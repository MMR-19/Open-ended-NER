Example #1: Popular recognition algorithms include principal component analysis using eigenface s, linear discriminant analysis, Elastic matching using the Fisherface algorithm, the hidden Markov model, the multilinear subspace learning using tensor representation, and the neuronal motivated dynamic link matching.
Expected output: 'entities: [{'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'eigenface', 'entity': 'Misc'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'Elastic matching', 'entity': 'Algorithm'}, {'span': 'Fisherface algorithm', 'entity': 'Algorithm'}, {'span': 'hidden Markov model', 'entity': 'Algorithm'}, {'span': 'multilinear subspace learning', 'entity': 'Algorithm'}, {'span': 'tensor representation', 'entity': 'Misc'}, {'span': 'dynamic link matching', 'entity': 'Algorithm'}]'

Example #2: As with BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentence s, the candidate translation string, and the reference translation string.
Expected output: 'entities: [{'span': 'BLEU', 'entity': 'Metrics'}]'

Example #3: An optimal value for math \ alpha / math can be found by using a line search algorithm, that is, the magnitude of math \ alpha / math is determined by finding the value that minimizes S, usually using a line search in the interval math0 \ alpha 1 / math or a backtracking line search such as Armijo-line search.
Expected output: 'entities: [{'span': 'line search algorithm', 'entity': 'Algorithm'}, {'span': 'line search', 'entity': 'Algorithm'}, {'span': 'backtracking line search', 'entity': 'Algorithm'}, {'span': 'Armijo-line search', 'entity': 'Algorithm'}]'

Example #4: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

Example #5: One of the metrics used in NIST ' s annual Document Understanding Conferences, in which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.
Expected output: 'entities: [{'span': "NIST ' s annual Document Understanding Conferences", 'entity': 'Conference'}, {'span': 'summarization', 'entity': 'Task'}, {'span': 'translation tasks', 'entity': 'Task'}, {'span': 'ROUGE metric', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}, {'span': 'Neural Information Processing Systems', 'entity': 'Conference'}, {'span': 'NIPS', 'entity': 'Conference'}, {'span': 'Montreal', 'entity': 'Location'}, {'span': 'Canada', 'entity': 'Country'}]'

