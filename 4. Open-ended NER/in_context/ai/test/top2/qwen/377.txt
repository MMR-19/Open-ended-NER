Example #1: Voice user interfaces that interpret and manage conversational state are challenging to design due to the inherent difficulty of integrating complex natural language processing tasks like coreference resolution, named-entity recognition, information retrieval, and dialog management.
Expected output: 'entities: [{'span': 'Voice user interfaces', 'entity': 'Product'}, {'span': 'natural language processing', 'entity': 'Field'}, {'span': 'coreference resolution', 'entity': 'Task'}, {'span': 'named-entity recognition', 'entity': 'Task'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'dialog management', 'entity': 'Task'}]'

Example #2: The input is called speech recognition and the output is called speech synthesis.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

