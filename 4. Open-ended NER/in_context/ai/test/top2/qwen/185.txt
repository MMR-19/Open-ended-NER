Example #1: One can use the OSD algorithm to derive math O (\ sqrt { T }) / math regret bounds for the online version of Support vector machine for classification, which use the hinge loss math v _ t (w) = \ max \ { 0, 1 - y _ t (w \ cdot x _ t) \ } / math
Expected output: 'entities: [{'span': 'OSD algorithm', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'classification', 'entity': 'Task'}, {'span': 'hinge loss', 'entity': 'Metrics'}]'

Example #2: Linear-fractional programming (LFP) is a generalization of linear programming (LP).
Expected output: 'entities: [{'span': 'Linear-fractional programming', 'entity': 'Algorithm'}, {'span': 'LFP', 'entity': 'Algorithm'}, {'span': 'linear programming', 'entity': 'Algorithm'}, {'span': 'LP', 'entity': 'Algorithm'}]'

