Example #1: In 2002 Hutter, with Jürgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealised intelligent agents and reward-motivated reinforcement learning.
Expected output: 'entities: [{'span': 'Hutter', 'entity': 'Researcher'}, {'span': 'Jürgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Shane Legg', 'entity': 'Researcher'}, {'span': 'artificial general intelligence', 'entity': 'Field'}, {'span': 'intelligent agents', 'entity': 'Misc'}, {'span': 'reinforcement learning', 'entity': 'Field'}]'

Example #2: Variants of the back-propagation algorithm as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly nonlinear neural architectures, { { cite journal
Expected output: 'entities: [{'span': 'back-propagation algorithm', 'entity': 'Algorithm'}, {'span': 'unsupervised methods', 'entity': 'Misc'}, {'span': 'Geoff Hinton', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

