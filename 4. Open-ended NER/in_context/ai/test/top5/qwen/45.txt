Example #1: Variants of the back-propagation algorithm as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly nonlinear neural architectures, { { cite journal
Expected output: 'entities: [{'span': 'back-propagation algorithm', 'entity': 'Algorithm'}, {'span': 'unsupervised methods', 'entity': 'Misc'}, {'span': 'Geoff Hinton', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

Example #2: DeepFace is a deep learning facial recognition system created by a research group at Facebook.
Expected output: 'entities: [{'span': 'DeepFace', 'entity': 'Product'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'facial recognition', 'entity': 'Task'}, {'span': 'Facebook', 'entity': 'Organisation'}]'

Example #3: Between 2009 and 2012, the recurrent neural network s and deep feedforward neural network s developed in the research group of J端rgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'deep feedforward neural network', 'entity': 'Algorithm'}, {'span': 'J端rgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Swiss AI Lab IDSIA', 'entity': 'Organisation'}, {'span': 'pattern recognition', 'entity': 'Field'}, {'span': 'machine learning', 'entity': 'Field'}]'

Example #4: In 2002 Hutter, with J端rgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealised intelligent agents and reward-motivated reinforcement learning.
Expected output: 'entities: [{'span': 'Hutter', 'entity': 'Researcher'}, {'span': 'J端rgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Shane Legg', 'entity': 'Researcher'}, {'span': 'artificial general intelligence', 'entity': 'Field'}, {'span': 'intelligent agents', 'entity': 'Misc'}, {'span': 'reinforcement learning', 'entity': 'Field'}]'

Example #5: The first attempt at end-to-end ASR was with Connectionist Temporal Classification (CTC) -based systems introduced by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto in 2014.
Expected output: 'entities: [{'span': 'end-to-end ASR', 'entity': 'Task'}, {'span': 'Connectionist Temporal Classification', 'entity': 'Algorithm'}, {'span': 'CTC', 'entity': 'Algorithm'}, {'span': 'Alex Graves', 'entity': 'Researcher'}, {'span': 'Google DeepMind', 'entity': 'Organisation'}, {'span': 'Navdeep Jaitly', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

