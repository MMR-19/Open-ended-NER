Example #1: An autoencoder is a type of artificial neural network used to learn Feature learning in an unsupervised learning manner.
Expected output: 'entities: [{'span': 'autoencoder', 'entity': 'Algorithm'}, {'span': 'artificial neural network', 'entity': 'Algorithm'}, {'span': 'Feature learning', 'entity': 'Task'}, {'span': 'unsupervised learning', 'entity': 'Field'}]'

Example #2: During the 1990s, encouraged by successes in speech recognition and speech synthesis, research began into speech translation with the development of the German Verbmobil project.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'speech translation', 'entity': 'Task'}, {'span': 'German', 'entity': 'Misc'}, {'span': 'Verbmobil project', 'entity': 'Misc'}]'

Example #3: Applications include object recognition, robotic mapping and navigation, image stitching, 3D modeling, gesture recognition, video tracking, individual identification of wildlife and match moving.
Expected output: 'entities: [{'span': 'object recognition', 'entity': 'Task'}, {'span': 'robotic mapping', 'entity': 'Task'}, {'span': 'navigation', 'entity': 'Task'}, {'span': 'image stitching', 'entity': 'Task'}, {'span': '3D modeling', 'entity': 'Task'}, {'span': 'gesture recognition', 'entity': 'Task'}, {'span': 'video tracking', 'entity': 'Task'}, {'span': 'individual identification of wildlife', 'entity': 'Task'}, {'span': 'match moving', 'entity': 'Task'}]'

Example #4: Advocates of procedural representations were mainly centered at MIT, under the leadership of Marvin Minsky and Seymour Papert.
Expected output: 'entities: [{'span': 'MIT', 'entity': 'University'}, {'span': 'Marvin Minsky', 'entity': 'Researcher'}, {'span': 'Seymour Papert', 'entity': 'Researcher'}]'

Example #5: Voice user interfaces that interpret and manage conversational state are challenging to design due to the inherent difficulty of integrating complex natural language processing tasks like coreference resolution, named-entity recognition, information retrieval, and dialog management.
Expected output: 'entities: [{'span': 'Voice user interfaces', 'entity': 'Product'}, {'span': 'natural language processing', 'entity': 'Field'}, {'span': 'coreference resolution', 'entity': 'Task'}, {'span': 'named-entity recognition', 'entity': 'Task'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'dialog management', 'entity': 'Task'}]'

Example #6: 59, pp. 2547-2553, Oct. 2011 In one dimensional polynomial-based memory (or memoryless) DPD, in order to solve for the digital pre-distorter polynomials coefficients and minimize the mean squared error (MSE), the distorted output of the nonlinear system must be over-sampled at a rate that enables the capture of the nonlinear products of the order of the digital pre-distorter.
Expected output: 'entities: [{'span': 'one dimensional polynomial-based memory', 'entity': 'Misc'}, {'span': 'DPD', 'entity': 'Misc'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #7: Popular approaches of opinion-based recommender system utilize various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.
Expected output: 'entities: [{'span': 'opinion-based recommender system', 'entity': 'Product'}, {'span': 'text mining', 'entity': 'Field'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'sentiment analysis', 'entity': 'Task'}, {'span': 'Multimodal sentiment analysis', 'entity': 'Task'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'X.Y. Feng', 'entity': 'Researcher'}, {'span': 'H. Zhang', 'entity': 'Researcher'}, {'span': 'Y.J. Ren', 'entity': 'Researcher'}, {'span': 'P.H. Shang', 'entity': 'Researcher'}, {'span': 'Y. Zhu', 'entity': 'Researcher'}, {'span': 'Y.C. Liang', 'entity': 'Researcher'}, {'span': 'R.C. Guan', 'entity': 'Researcher'}, {'span': 'D. Xu', 'entity': 'Researcher'}]'

Example #8: or equivalently using DCG notation:
Expected output: 'entities: [{'span': 'DCG', 'entity': 'Metrics'}]'

Example #9: Between 2009 and 2012, the recurrent neural network s and deep feedforward neural network s developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'deep feedforward neural network', 'entity': 'Algorithm'}, {'span': 'Jürgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Swiss AI Lab IDSIA', 'entity': 'Organisation'}, {'span': 'pattern recognition', 'entity': 'Field'}, {'span': 'machine learning', 'entity': 'Field'}]'

Example #10: One can use the OSD algorithm to derive math O (\ sqrt { T }) / math regret bounds for the online version of Support vector machine for classification, which use the hinge loss math v _ t (w) = \ max \ { 0, 1 - y _ t (w \ cdot x _ t) \ } / math
Expected output: 'entities: [{'span': 'OSD algorithm', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'classification', 'entity': 'Task'}, {'span': 'hinge loss', 'entity': 'Metrics'}]'

