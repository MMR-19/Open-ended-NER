Example #1: Artificial neural networks are computational models that excel at machine learning and pattern recognition.
Expected output: 'entities: [{'span': 'Artificial neural networks', 'entity': 'Algorithm'}, {'span': 'machine learning', 'entity': 'Field'}, {'span': 'pattern recognition', 'entity': 'Field'}]'

Example #2: During the 1990s, encouraged by successes in speech recognition and speech synthesis, research began into speech translation with the development of the German Verbmobil project.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'speech translation', 'entity': 'Task'}, {'span': 'German', 'entity': 'Misc'}, {'span': 'Verbmobil project', 'entity': 'Misc'}]'

Example #3: Lafferty received numerous awards, including two Test-of-Time awards at the International Conference on Machine Learning 2011 & 2012,
Expected output: 'entities: [{'span': 'Lafferty', 'entity': 'Researcher'}, {'span': 'Test-of-Time awards', 'entity': 'Misc'}, {'span': 'International Conference on Machine Learning 2011 & 2012', 'entity': 'Conference'}]'

Example #4: Several other features that helped put 3D back on the map that month were the John Wayne feature Hondo (distributed by Warner Bros.), Columbia's Miss Sadie Thompson with Rita Hayworth, and Paramount's Money From Home with Dean Martin and Jerry Lewis.
Expected output: 'entities: [{'span': 'John Wayne', 'entity': 'Person'}, {'span': 'Hondo', 'entity': 'Misc'}, {'span': 'Warner Bros.', 'entity': 'Organisation'}, {'span': 'Columbia', 'entity': 'Organisation'}, {'span': 'Miss Sadie Thompson', 'entity': 'Misc'}, {'span': 'Rita Hayworth', 'entity': 'Person'}, {'span': 'Paramount', 'entity': 'Organisation'}, {'span': 'Money From Home', 'entity': 'Misc'}, {'span': 'Dean Martin', 'entity': 'Person'}, {'span': 'Jerry Lewis', 'entity': 'Person'}]'

Example #5: The sigmoid function s and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, these were released in a separate R package sigmoid, with the intention to enable more general use.
Expected output: 'entities: [{'span': 'sigmoid function', 'entity': 'Algorithm'}, {'span': 'R', 'entity': 'Programming Language'}, {'span': 'sigmoid', 'entity': 'Algorithm'}]'

Example #6: Advocates of procedural representations were mainly centered at MIT, under the leadership of Marvin Minsky and Seymour Papert.
Expected output: 'entities: [{'span': 'MIT', 'entity': 'University'}, {'span': 'Marvin Minsky', 'entity': 'Researcher'}, {'span': 'Seymour Papert', 'entity': 'Researcher'}]'

Example #7: This math \ theta ^ { * } / math is normally estimated using a Maximum Likelihood (math \ theta ^ { * } = \ theta ^ { ML } / math) or Maximum A Posteriori (math \ theta ^ { * } = \ theta ^ { MAP } / math) procedure.
Expected output: 'entities: [{'span': 'Maximum Likelihood', 'entity': 'Algorithm'}, {'span': 'Maximum A Posteriori', 'entity': 'Algorithm'}, {'span': 'MAP', 'entity': 'Algorithm'}]'

Example #8: Libraries written in Perl, Java, ActiveX or .NET can be directly called from MATLAB,
Expected output: 'entities: [{'span': 'Perl', 'entity': 'Programming Language'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'ActiveX', 'entity': 'Programming Language'}, {'span': '.NET', 'entity': 'Programming Language'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #9: The company has international locations in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, the Philippines, Russia, Singapore, South Africa, Spain, Taiwan, Thailand, Turkey and the United Kingdom.
Expected output: 'entities: [{'span': 'Australia', 'entity': 'Country'}, {'span': 'Brazil', 'entity': 'Country'}, {'span': 'Canada', 'entity': 'Country'}, {'span': 'China', 'entity': 'Country'}, {'span': 'Germany', 'entity': 'Country'}, {'span': 'India', 'entity': 'Country'}, {'span': 'Italy', 'entity': 'Country'}, {'span': 'Japan', 'entity': 'Country'}, {'span': 'Korea', 'entity': 'Country'}, {'span': 'Lithuania', 'entity': 'Country'}, {'span': 'Poland', 'entity': 'Country'}, {'span': 'Malaysia', 'entity': 'Country'}, {'span': 'Philippines', 'entity': 'Country'}, {'span': 'Russia', 'entity': 'Country'}, {'span': 'Singapore', 'entity': 'Country'}, {'span': 'South Africa', 'entity': 'Country'}, {'span': 'Spain', 'entity': 'Country'}, {'span': 'Taiwan', 'entity': 'Country'}, {'span': 'Thailand', 'entity': 'Country'}, {'span': 'Turkey', 'entity': 'Country'}, {'span': 'United Kingdom', 'entity': 'Country'}]'

Example #10: Another technique particularly used for recurrent neural network s is the long short-term memory (LSTM) network of 1997 by Sepp Hochreiter & Jürgen Schmidhuber.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'long short-term memory', 'entity': 'Algorithm'}, {'span': 'LSTM', 'entity': 'Algorithm'}, {'span': 'Sepp Hochreiter', 'entity': 'Researcher'}, {'span': 'Jürgen Schmidhuber', 'entity': 'Researcher'}]'

