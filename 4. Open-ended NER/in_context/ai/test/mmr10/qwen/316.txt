Example #1: Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.
Expected output: 'entities: [{'span': 'unsupervised learning', 'entity': 'Field'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'cluster analysis', 'entity': 'Task'}]'

Example #2: One can use the OSD algorithm to derive math O (\ sqrt { T }) / math regret bounds for the online version of Support vector machine for classification, which use the hinge loss math v _ t (w) = \ max \ { 0, 1 - y _ t (w \ cdot x _ t) \ } / math
Expected output: 'entities: [{'span': 'OSD algorithm', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'classification', 'entity': 'Task'}, {'span': 'hinge loss', 'entity': 'Metrics'}]'

Example #3: Linear-fractional programming (LFP) is a generalization of linear programming (LP).
Expected output: 'entities: [{'span': 'Linear-fractional programming', 'entity': 'Algorithm'}, {'span': 'LFP', 'entity': 'Algorithm'}, {'span': 'linear programming', 'entity': 'Algorithm'}, {'span': 'LP', 'entity': 'Algorithm'}]'

Example #4: J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.
Expected output: 'entities: [{'span': 'J48', 'entity': 'Product'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'C4.5 algorithm', 'entity': 'Algorithm'}, {'span': 'Weka data mining tool', 'entity': 'Product'}]'

Example #5: Examples of supervised learning are Naive Bayes classifier, Support vector machine, mixtures of Gaussians, and network.
Expected output: 'entities: [{'span': 'supervised learning', 'entity': 'Field'}, {'span': 'Naive Bayes classifier', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'mixtures of Gaussians', 'entity': 'Algorithm'}, {'span': 'network', 'entity': 'Algorithm'}]'

Example #6: The input is called speech recognition and the output is called speech synthesis.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #7: Self-organizing maps differ from other artificial neural networks as they apply competitive learning as opposed to error-correction learning such as backpropagation with gradient descent), and in the sense that they use a neighborhood function to preserve the topological properties of the input space.
Expected output: 'entities: [{'span': 'artificial neural networks', 'entity': 'Algorithm'}, {'span': 'competitive learning', 'entity': 'Algorithm'}, {'span': 'error-correction learning', 'entity': 'Algorithm'}, {'span': 'backpropagation', 'entity': 'Algorithm'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'topological properties', 'entity': 'Misc'}]'

Example #8: Lafferty received numerous awards, including two Test-of-Time awards at the International Conference on Machine Learning 2011 & 2012,
Expected output: 'entities: [{'span': 'Lafferty', 'entity': 'Researcher'}, {'span': 'Test-of-Time awards', 'entity': 'Misc'}, {'span': 'International Conference on Machine Learning 2011 & 2012', 'entity': 'Conference'}]'

Example #9: This math \ theta ^ { * } / math is normally estimated using a Maximum Likelihood (math \ theta ^ { * } = \ theta ^ { ML } / math) or Maximum A Posteriori (math \ theta ^ { * } = \ theta ^ { MAP } / math) procedure.
Expected output: 'entities: [{'span': 'Maximum Likelihood', 'entity': 'Algorithm'}, {'span': 'Maximum A Posteriori', 'entity': 'Algorithm'}, {'span': 'MAP', 'entity': 'Algorithm'}]'

Example #10: A typical factory contains hundreds of industrial robot s working on fully automated production lines, with one robot for every ten human workers.
Expected output: 'entities: [{'span': 'industrial robot', 'entity': 'Product'}]'

