Example #1: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #2: As for the results, the C-HOG and R-HOG block descriptors perform comparably, with the C-HOG descriptors maintaining a slight advantage in the detection miss rate at fixed FALSE positive rate s across both data sets.
Expected output: 'entities: [{'span': 'C-HOG', 'entity': 'Algorithm'}, {'span': 'R-HOG', 'entity': 'Algorithm'}, {'span': 'C-HOG descriptors', 'entity': 'Algorithm'}, {'span': 'FALSE positive rate', 'entity': 'Metrics'}]'

Example #3: Variants of the back-propagation algorithm as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly nonlinear neural architectures, { { cite journal
Expected output: 'entities: [{'span': 'back-propagation algorithm', 'entity': 'Algorithm'}, {'span': 'unsupervised methods', 'entity': 'Misc'}, {'span': 'Geoff Hinton', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

Example #4: It also created flexible intelligent AGV applications, designing the Motivity control system used by RMT Robotics to develop its ADAM iAGV (Self-Guided Vehicle), used for complex pick and place operations, in conjunction with gantry systems and industrial robot arms, used in first-tier auto supply factories to move products from process to process in non-linear layouts.
Expected output: 'entities: [{'span': 'AGV', 'entity': 'Product'}, {'span': 'Motivity control system', 'entity': 'Product'}, {'span': 'RMT Robotics', 'entity': 'Organisation'}, {'span': 'ADAM iAGV', 'entity': 'Product'}, {'span': 'gantry systems', 'entity': 'Product'}, {'span': 'industrial robot arms', 'entity': 'Product'}, {'span': 'non-linear layouts', 'entity': 'Misc'}]'

Example #5: Popular approaches of opinion-based recommender system utilize various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.
Expected output: 'entities: [{'span': 'opinion-based recommender system', 'entity': 'Product'}, {'span': 'text mining', 'entity': 'Field'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'sentiment analysis', 'entity': 'Task'}, {'span': 'Multimodal sentiment analysis', 'entity': 'Task'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'X.Y. Feng', 'entity': 'Researcher'}, {'span': 'H. Zhang', 'entity': 'Researcher'}, {'span': 'Y.J. Ren', 'entity': 'Researcher'}, {'span': 'P.H. Shang', 'entity': 'Researcher'}, {'span': 'Y. Zhu', 'entity': 'Researcher'}, {'span': 'Y.C. Liang', 'entity': 'Researcher'}, {'span': 'R.C. Guan', 'entity': 'Researcher'}, {'span': 'D. Xu', 'entity': 'Researcher'}]'

Example #6: Several other features that helped put 3D back on the map that month were the John Wayne feature Hondo (distributed by Warner Bros.), Columbia's Miss Sadie Thompson with Rita Hayworth, and Paramount's Money From Home with Dean Martin and Jerry Lewis.
Expected output: 'entities: [{'span': 'John Wayne', 'entity': 'Person'}, {'span': 'Hondo', 'entity': 'Misc'}, {'span': 'Warner Bros.', 'entity': 'Organisation'}, {'span': 'Columbia', 'entity': 'Organisation'}, {'span': 'Miss Sadie Thompson', 'entity': 'Misc'}, {'span': 'Rita Hayworth', 'entity': 'Person'}, {'span': 'Paramount', 'entity': 'Organisation'}, {'span': 'Money From Home', 'entity': 'Misc'}, {'span': 'Dean Martin', 'entity': 'Person'}, {'span': 'Jerry Lewis', 'entity': 'Person'}]'

Example #7: Lafferty received numerous awards, including two Test-of-Time awards at the International Conference on Machine Learning 2011 & 2012,
Expected output: 'entities: [{'span': 'Lafferty', 'entity': 'Researcher'}, {'span': 'Test-of-Time awards', 'entity': 'Misc'}, {'span': 'International Conference on Machine Learning 2011 & 2012', 'entity': 'Conference'}]'

Example #8: This math \ theta ^ { * } / math is normally estimated using a Maximum Likelihood (math \ theta ^ { * } = \ theta ^ { ML } / math) or Maximum A Posteriori (math \ theta ^ { * } = \ theta ^ { MAP } / math) procedure.
Expected output: 'entities: [{'span': 'Maximum Likelihood', 'entity': 'Algorithm'}, {'span': 'Maximum A Posteriori', 'entity': 'Algorithm'}, {'span': 'MAP', 'entity': 'Algorithm'}]'

Example #9: Examples of supervised learning are Naive Bayes classifier, Support vector machine, mixtures of Gaussians, and network.
Expected output: 'entities: [{'span': 'supervised learning', 'entity': 'Field'}, {'span': 'Naive Bayes classifier', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'mixtures of Gaussians', 'entity': 'Algorithm'}, {'span': 'network', 'entity': 'Algorithm'}]'

Example #10: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

