Example #1: Between 2009 and 2012, the recurrent neural network s and deep feedforward neural network s developed in the research group of J端rgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'deep feedforward neural network', 'entity': 'Algorithm'}, {'span': 'J端rgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Swiss AI Lab IDSIA', 'entity': 'Organisation'}, {'span': 'pattern recognition', 'entity': 'Field'}, {'span': 'machine learning', 'entity': 'Field'}]'

Example #2: A fast method for computing maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss ' work in 1935.
Expected output: 'entities: [{'span': 'maximum likelihood', 'entity': 'Metrics'}, {'span': 'probit model', 'entity': 'Algorithm'}, {'span': 'Ronald Fisher', 'entity': 'Researcher'}, {'span': 'Bliss', 'entity': 'Researcher'}]'

Example #3: Variants of the back-propagation algorithm as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly nonlinear neural architectures, { { cite journal
Expected output: 'entities: [{'span': 'back-propagation algorithm', 'entity': 'Algorithm'}, {'span': 'unsupervised methods', 'entity': 'Misc'}, {'span': 'Geoff Hinton', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

Example #4: Advocates of procedural representations were mainly centered at MIT, under the leadership of Marvin Minsky and Seymour Papert.
Expected output: 'entities: [{'span': 'MIT', 'entity': 'University'}, {'span': 'Marvin Minsky', 'entity': 'Researcher'}, {'span': 'Seymour Papert', 'entity': 'Researcher'}]'

Example #5: During the 1990s, encouraged by successes in speech recognition and speech synthesis, research began into speech translation with the development of the German Verbmobil project.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'speech translation', 'entity': 'Task'}, {'span': 'German', 'entity': 'Misc'}, {'span': 'Verbmobil project', 'entity': 'Misc'}]'

Example #6: Several other features that helped put 3D back on the map that month were the John Wayne feature Hondo (distributed by Warner Bros.), Columbia's Miss Sadie Thompson with Rita Hayworth, and Paramount's Money From Home with Dean Martin and Jerry Lewis.
Expected output: 'entities: [{'span': 'John Wayne', 'entity': 'Person'}, {'span': 'Hondo', 'entity': 'Misc'}, {'span': 'Warner Bros.', 'entity': 'Organisation'}, {'span': 'Columbia', 'entity': 'Organisation'}, {'span': 'Miss Sadie Thompson', 'entity': 'Misc'}, {'span': 'Rita Hayworth', 'entity': 'Person'}, {'span': 'Paramount', 'entity': 'Organisation'}, {'span': 'Money From Home', 'entity': 'Misc'}, {'span': 'Dean Martin', 'entity': 'Person'}, {'span': 'Jerry Lewis', 'entity': 'Person'}]'

Example #7: Linear predictive coding (LPC), a form of speech coding, began development with the work Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.
Expected output: 'entities: [{'span': 'Linear predictive coding', 'entity': 'Algorithm'}, {'span': 'LPC', 'entity': 'Algorithm'}, {'span': 'speech coding', 'entity': 'Task'}, {'span': 'Fumitada Itakura', 'entity': 'Researcher'}, {'span': 'Nagoya University', 'entity': 'University'}, {'span': 'Shuzo Saito', 'entity': 'Researcher'}, {'span': 'Nippon Telegraph and Telephone', 'entity': 'University'}, {'span': 'NTT', 'entity': 'University'}]'

Example #8: tity contains a collection of visualization tools and algorithms for data analysis and predictive modeling, together with graphical user interfaces for easy access to these functions. but the more recent fully Java -based version (Weka 3), for which development started in 1997, is now used in many different application areas, in particular for educational purposes and research.
Expected output: 'entities: [{'span': 'tity', 'entity': 'Product'}, {'span': 'data analysis', 'entity': 'Field'}, {'span': 'predictive modeling', 'entity': 'Task'}, {'span': 'graphical user interfaces', 'entity': 'Misc'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'Weka 3', 'entity': 'Product'}]'

Example #9: In 1999, Felix Gers and his advisor J端rgen Schmidhuber and Fred Cummins introduced the forget gate (also called keep gate) into LSTM architecture,
Expected output: 'entities: [{'span': 'Felix Gers', 'entity': 'Researcher'}, {'span': 'J端rgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Fred Cummins', 'entity': 'Researcher'}, {'span': 'forget gate', 'entity': 'Algorithm'}, {'span': 'keep gate', 'entity': 'Algorithm'}, {'span': 'LSTM', 'entity': 'Algorithm'}]'

Example #10: Since the early 1990s, it has been recommended by several authorities, including the Audio Engineering Society that measurements of dynamic range be made with an audio signal present, which is then filtered out in the noise floor measurement used in determining dynamic range. This avoids questionable measurements based on the use of blank media, or muting circuits.
Expected output: 'entities: [{'span': 'Audio Engineering Society', 'entity': 'Organisation'}, {'span': 'audio signal', 'entity': 'Misc'}, {'span': 'noise floor measurement', 'entity': 'Metrics'}]'

