Example #1: Over the past decade, PCNNs have been used in a variety of image processing applications, including: image segmentation, feature generation, face extraction, motion detection, region growing, and noise reduction.
Expected output: 'entities: [{'span': 'PCNNs', 'entity': 'Product'}, {'span': 'image processing', 'entity': 'Field'}, {'span': 'image segmentation', 'entity': 'Task'}, {'span': 'feature generation', 'entity': 'Task'}, {'span': 'face extraction', 'entity': 'Task'}, {'span': 'motion detection', 'entity': 'Task'}, {'span': 'region growing', 'entity': 'Task'}, {'span': 'noise reduction', 'entity': 'Task'}]'

Example #2: One can use the OSD algorithm to derive math O (\ sqrt { T }) / math regret bounds for the online version of Support vector machine for classification, which use the hinge loss math v _ t (w) = \ max \ { 0, 1 - y _ t (w \ cdot x _ t) \ } / math
Expected output: 'entities: [{'span': 'OSD algorithm', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'classification', 'entity': 'Task'}, {'span': 'hinge loss', 'entity': 'Metrics'}]'

Example #3: The task of recognizing named entities in text is Named Entity Recognition while the task of determining the identity of the named entities mentioned in text is called Entity Linking.
Expected output: 'entities: [{'span': 'recognizing named entities in text', 'entity': 'Task'}, {'span': 'Named Entity Recognition', 'entity': 'Task'}, {'span': 'Entity Linking', 'entity': 'Task'}]'

Example #4: Geometry processing is a common research topic at SIGGRAPH, the premier computer graphics academic conference, and the main topic of the annual Symposium on Geometry Processing.
Expected output: 'entities: [{'span': 'Geometry processing', 'entity': 'Field'}, {'span': 'SIGGRAPH', 'entity': 'Conference'}, {'span': 'computer graphics', 'entity': 'Field'}, {'span': 'Symposium on Geometry Processing', 'entity': 'Conference'}]'

Example #5: The inclusion of a C + + interpreter (CINT until version 5.34, Cling from version 6) makes this package very versatile as it can be used in interactive, scripted and compiled modes in a manner similar to commercial products like MATLAB.
Expected output: 'entities: [{'span': 'C + +', 'entity': 'Programming Language'}, {'span': 'CINT', 'entity': 'Product'}, {'span': 'Cling', 'entity': 'Product'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #6: As for the results, the C-HOG and R-HOG block descriptors perform comparably, with the C-HOG descriptors maintaining a slight advantage in the detection miss rate at fixed FALSE positive rate s across both data sets.
Expected output: 'entities: [{'span': 'C-HOG', 'entity': 'Algorithm'}, {'span': 'R-HOG', 'entity': 'Algorithm'}, {'span': 'C-HOG descriptors', 'entity': 'Algorithm'}, {'span': 'FALSE positive rate', 'entity': 'Metrics'}]'

Example #7: Haralick is a Fellow of IEEE for his contributions in computer vision and image processing and a Fellow of the International Association for Pattern Recognition (IAPR) for his contributions in pattern recognition, image processing, and for service to IAPR.
Expected output: 'entities: [{'span': 'Haralick', 'entity': 'Researcher'}, {'span': 'IEEE', 'entity': 'Organisation'}, {'span': 'computer vision', 'entity': 'Field'}, {'span': 'image processing', 'entity': 'Field'}, {'span': 'International Association for Pattern Recognition', 'entity': 'Organisation'}, {'span': 'IAPR', 'entity': 'Organisation'}, {'span': 'pattern recognition', 'entity': 'Field'}]'

Example #8: Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'non-negative matrix factorization', 'entity': 'Algorithm'}, {'span': 'NMF', 'entity': 'Algorithm'}, {'span': 'pre-processing step', 'entity': 'Misc'}, {'span': 'K-NN', 'entity': 'Algorithm'}, {'span': 'feature vectors', 'entity': 'Misc'}]'

Example #9: Applications include object recognition, robotic mapping and navigation, image stitching, 3D modeling, gesture recognition, video tracking, individual identification of wildlife and match moving.
Expected output: 'entities: [{'span': 'object recognition', 'entity': 'Task'}, {'span': 'robotic mapping', 'entity': 'Task'}, {'span': 'navigation', 'entity': 'Task'}, {'span': 'image stitching', 'entity': 'Task'}, {'span': '3D modeling', 'entity': 'Task'}, {'span': 'gesture recognition', 'entity': 'Task'}, {'span': 'video tracking', 'entity': 'Task'}, {'span': 'individual identification of wildlife', 'entity': 'Task'}, {'span': 'match moving', 'entity': 'Task'}]'

Example #10: Variants of the back-propagation algorithm as well as unsupervised methods by Geoff Hinton and colleagues at the University of Toronto can be used to train deep, highly nonlinear neural architectures, { { cite journal
Expected output: 'entities: [{'span': 'back-propagation algorithm', 'entity': 'Algorithm'}, {'span': 'unsupervised methods', 'entity': 'Misc'}, {'span': 'Geoff Hinton', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

