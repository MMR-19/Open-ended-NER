Example #1: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #2: J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.
Expected output: 'entities: [{'span': 'J48', 'entity': 'Product'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'C4.5 algorithm', 'entity': 'Algorithm'}, {'span': 'Weka data mining tool', 'entity': 'Product'}]'

Example #3: Poggio is an honorary member of the Neuroscience Research Program, a member of the American Academy of Arts and Sciences and a founding fellow of AAAI and a founding member of the McGovern Institute for Brain Research.
Expected output: 'entities: [{'span': 'Poggio', 'entity': 'Researcher'}, {'span': 'Neuroscience Research Program', 'entity': 'Organisation'}, {'span': 'American Academy of Arts and Sciences', 'entity': 'Organisation'}, {'span': 'AAAI', 'entity': 'Conference'}, {'span': 'McGovern Institute for Brain Research', 'entity': 'Organisation'}]'

Example #4: The NIST metric is based on the BLEU metric, but with some alterations.
Expected output: 'entities: [{'span': 'NIST metric', 'entity': 'Metrics'}, {'span': 'BLEU metric', 'entity': 'Metrics'}]'

Example #5: Popular approaches of opinion-based recommender system utilize various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.
Expected output: 'entities: [{'span': 'opinion-based recommender system', 'entity': 'Product'}, {'span': 'text mining', 'entity': 'Field'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'sentiment analysis', 'entity': 'Task'}, {'span': 'Multimodal sentiment analysis', 'entity': 'Task'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'X.Y. Feng', 'entity': 'Researcher'}, {'span': 'H. Zhang', 'entity': 'Researcher'}, {'span': 'Y.J. Ren', 'entity': 'Researcher'}, {'span': 'P.H. Shang', 'entity': 'Researcher'}, {'span': 'Y. Zhu', 'entity': 'Researcher'}, {'span': 'Y.C. Liang', 'entity': 'Researcher'}, {'span': 'R.C. Guan', 'entity': 'Researcher'}, {'span': 'D. Xu', 'entity': 'Researcher'}]'

Example #6: The company has international locations in Australia, Brazil, Canada, China, Germany, India, Italy, Japan, Korea, Lithuania, Poland, Malaysia, the Philippines, Russia, Singapore, South Africa, Spain, Taiwan, Thailand, Turkey and the United Kingdom.
Expected output: 'entities: [{'span': 'Australia', 'entity': 'Country'}, {'span': 'Brazil', 'entity': 'Country'}, {'span': 'Canada', 'entity': 'Country'}, {'span': 'China', 'entity': 'Country'}, {'span': 'Germany', 'entity': 'Country'}, {'span': 'India', 'entity': 'Country'}, {'span': 'Italy', 'entity': 'Country'}, {'span': 'Japan', 'entity': 'Country'}, {'span': 'Korea', 'entity': 'Country'}, {'span': 'Lithuania', 'entity': 'Country'}, {'span': 'Poland', 'entity': 'Country'}, {'span': 'Malaysia', 'entity': 'Country'}, {'span': 'Philippines', 'entity': 'Country'}, {'span': 'Russia', 'entity': 'Country'}, {'span': 'Singapore', 'entity': 'Country'}, {'span': 'South Africa', 'entity': 'Country'}, {'span': 'Spain', 'entity': 'Country'}, {'span': 'Taiwan', 'entity': 'Country'}, {'span': 'Thailand', 'entity': 'Country'}, {'span': 'Turkey', 'entity': 'Country'}, {'span': 'United Kingdom', 'entity': 'Country'}]'

Example #7: Linear-fractional programming (LFP) is a generalization of linear programming (LP).
Expected output: 'entities: [{'span': 'Linear-fractional programming', 'entity': 'Algorithm'}, {'span': 'LFP', 'entity': 'Algorithm'}, {'span': 'linear programming', 'entity': 'Algorithm'}, {'span': 'LP', 'entity': 'Algorithm'}]'

Example #8: Several of these programs are available online, such as Google Translate and the SYSTRAN system that powers AltaVista's BabelFish (now Yahoo's Babelfish as of 9 May 2008).
Expected output: 'entities: [{'span': 'Google Translate', 'entity': 'Product'}, {'span': 'SYSTRAN system', 'entity': 'Product'}, {'span': 'AltaVista', 'entity': 'Organisation'}, {'span': 'BabelFish', 'entity': 'Product'}, {'span': 'Yahoo', 'entity': 'Organisation'}, {'span': 'Babelfish', 'entity': 'Product'}]'

Example #9: Since 2002, perceptron training has become popular in the field of natural language processing for such tasks as part-of-speech tagging and syntactic parsing (Collins, 2002).
Expected output: 'entities: [{'span': 'natural language processing', 'entity': 'Field'}, {'span': 'part-of-speech tagging', 'entity': 'Task'}, {'span': 'syntactic parsing', 'entity': 'Task'}, {'span': 'Collins', 'entity': 'Researcher'}]'

Example #10: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

