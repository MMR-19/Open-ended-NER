Example #1: The term computational linguistics itself was first coined by David Hays, a founding member of both the Association for Computational Linguistics and the International Committee on Computational Linguistics (ICCL).
Expected output: 'entities: [{'span': 'computational linguistics', 'entity': 'Field'}, {'span': 'David Hays', 'entity': 'Researcher'}, {'span': 'Association for Computational Linguistics', 'entity': 'Conference'}, {'span': 'International Committee on Computational Linguistics', 'entity': 'Organisation'}, {'span': 'ICCL', 'entity': 'Organisation'}]'

Example #2: Examples of supervised learning are Naive Bayes classifier, Support vector machine, mixtures of Gaussians, and network.
Expected output: 'entities: [{'span': 'supervised learning', 'entity': 'Field'}, {'span': 'Naive Bayes classifier', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'mixtures of Gaussians', 'entity': 'Algorithm'}, {'span': 'network', 'entity': 'Algorithm'}]'

Example #3: Licensing the original patent awarded to inventor George Devol, Engelberger developed the first industrial robot in the United States, the Unimate, in the 1950s.
Expected output: 'entities: [{'span': 'George Devol', 'entity': 'Researcher'}, {'span': 'Engelberger', 'entity': 'Researcher'}, {'span': 'industrial robot', 'entity': 'Product'}, {'span': 'United States', 'entity': 'Country'}, {'span': 'Unimate', 'entity': 'Product'}]'

Example #4: Lafferty received numerous awards, including two Test-of-Time awards at the International Conference on Machine Learning 2011 & 2012,
Expected output: 'entities: [{'span': 'Lafferty', 'entity': 'Researcher'}, {'span': 'Test-of-Time awards', 'entity': 'Misc'}, {'span': 'International Conference on Machine Learning 2011 & 2012', 'entity': 'Conference'}]'

Example #5: In 1999, Felix Gers and his advisor J端rgen Schmidhuber and Fred Cummins introduced the forget gate (also called keep gate) into LSTM architecture,
Expected output: 'entities: [{'span': 'Felix Gers', 'entity': 'Researcher'}, {'span': 'J端rgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Fred Cummins', 'entity': 'Researcher'}, {'span': 'forget gate', 'entity': 'Algorithm'}, {'span': 'keep gate', 'entity': 'Algorithm'}, {'span': 'LSTM', 'entity': 'Algorithm'}]'

Example #6: In 2002 Hutter, with J端rgen Schmidhuber and Shane Legg, developed and published a mathematical theory of artificial general intelligence based on idealised intelligent agents and reward-motivated reinforcement learning.
Expected output: 'entities: [{'span': 'Hutter', 'entity': 'Researcher'}, {'span': 'J端rgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Shane Legg', 'entity': 'Researcher'}, {'span': 'artificial general intelligence', 'entity': 'Field'}, {'span': 'intelligent agents', 'entity': 'Misc'}, {'span': 'reinforcement learning', 'entity': 'Field'}]'

Example #7: Logo was created in 1967 at Bolt, Beranek and Newman (BBN), a Cambridge, Massachusetts research firm, by Wally Feurzeig, Cynthia Solomon, and Seymour Papert.
Expected output: 'entities: [{'span': 'Logo', 'entity': 'Programming Language'}, {'span': 'Bolt, Beranek and Newman', 'entity': 'Organisation'}, {'span': 'BBN', 'entity': 'Organisation'}, {'span': 'Cambridge', 'entity': 'University'}, {'span': 'Massachusetts', 'entity': 'University'}, {'span': 'Wally Feurzeig', 'entity': 'Researcher'}, {'span': 'Cynthia Solomon', 'entity': 'Researcher'}, {'span': 'Seymour Papert', 'entity': 'Researcher'}]'

Example #8: A fast method for computing maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss ' work in 1935.
Expected output: 'entities: [{'span': 'maximum likelihood', 'entity': 'Metrics'}, {'span': 'probit model', 'entity': 'Algorithm'}, {'span': 'Ronald Fisher', 'entity': 'Researcher'}, {'span': 'Bliss', 'entity': 'Researcher'}]'

Example #9: Since 2002, perceptron training has become popular in the field of natural language processing for such tasks as part-of-speech tagging and syntactic parsing (Collins, 2002).
Expected output: 'entities: [{'span': 'natural language processing', 'entity': 'Field'}, {'span': 'part-of-speech tagging', 'entity': 'Task'}, {'span': 'syntactic parsing', 'entity': 'Task'}, {'span': 'Collins', 'entity': 'Researcher'}]'

Example #10: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

