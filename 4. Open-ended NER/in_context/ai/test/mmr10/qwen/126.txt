Example #1: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #2: He held the Johann Bernoulli Chair of Mathematics and Informatics at the University of Groningen in the Netherlands, and the Toshiba Endowed Chair at the Tokyo Institute of Technology in Japan before becoming Professor at Cambridge.
Expected output: 'entities: [{'span': 'Johann Bernoulli Chair', 'entity': 'Misc'}, {'span': 'Mathematics', 'entity': 'Field'}, {'span': 'Informatics', 'entity': 'Field'}, {'span': 'University of Groningen', 'entity': 'University'}, {'span': 'Netherlands', 'entity': 'Country'}, {'span': 'Toshiba Endowed Chair', 'entity': 'Misc'}, {'span': 'Tokyo Institute of Technology', 'entity': 'University'}, {'span': 'Japan', 'entity': 'Country'}, {'span': 'Cambridge', 'entity': 'University'}]'

Example #3: Lafferty received numerous awards, including two Test-of-Time awards at the International Conference on Machine Learning 2011 & 2012,
Expected output: 'entities: [{'span': 'Lafferty', 'entity': 'Researcher'}, {'span': 'Test-of-Time awards', 'entity': 'Misc'}, {'span': 'International Conference on Machine Learning 2011 & 2012', 'entity': 'Conference'}]'

Example #4: Since 2002, perceptron training has become popular in the field of natural language processing for such tasks as part-of-speech tagging and syntactic parsing (Collins, 2002).
Expected output: 'entities: [{'span': 'natural language processing', 'entity': 'Field'}, {'span': 'part-of-speech tagging', 'entity': 'Task'}, {'span': 'syntactic parsing', 'entity': 'Task'}, {'span': 'Collins', 'entity': 'Researcher'}]'

Example #5: CycL in computer science and artificial intelligence is an ontology language used by Doug Lenat's Cyc artificial project.
Expected output: 'entities: [{'span': 'CycL', 'entity': 'Programming Language'}, {'span': 'computer science', 'entity': 'Field'}, {'span': 'artificial intelligence', 'entity': 'Field'}, {'span': 'ontology language', 'entity': 'Misc'}, {'span': 'Doug Lenat', 'entity': 'Researcher'}, {'span': 'Cyc artificial project', 'entity': 'Misc'}]'

Example #6: The National Science Foundation was an umbrella for the National Aeronautics and Space Administration (NASA), the US Department of Energy, the US Department of Commerce NIST, the US Department of Defense, Defense Advanced Research Projects Agency (DARPA), and the Office of Naval Research coordinated studies to inform strategic planners in their deliberations.
Expected output: 'entities: [{'span': 'National Science Foundation', 'entity': 'Organisation'}, {'span': 'National Aeronautics and Space Administration', 'entity': 'Organisation'}, {'span': 'NASA', 'entity': 'Organisation'}, {'span': 'US Department of Energy', 'entity': 'Organisation'}, {'span': 'US Department of Commerce NIST', 'entity': 'Organisation'}, {'span': 'US Department of Defense', 'entity': 'Organisation'}, {'span': 'Defense Advanced Research Projects Agency', 'entity': 'Organisation'}, {'span': 'DARPA', 'entity': 'Organisation'}, {'span': 'Office of Naval Research', 'entity': 'Organisation'}]'

Example #7: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

Example #8: This math \ theta ^ { * } / math is normally estimated using a Maximum Likelihood (math \ theta ^ { * } = \ theta ^ { ML } / math) or Maximum A Posteriori (math \ theta ^ { * } = \ theta ^ { MAP } / math) procedure.
Expected output: 'entities: [{'span': 'Maximum Likelihood', 'entity': 'Algorithm'}, {'span': 'Maximum A Posteriori', 'entity': 'Algorithm'}, {'span': 'MAP', 'entity': 'Algorithm'}]'

Example #9: Geometry processing is a common research topic at SIGGRAPH, the premier computer graphics academic conference, and the main topic of the annual Symposium on Geometry Processing.
Expected output: 'entities: [{'span': 'Geometry processing', 'entity': 'Field'}, {'span': 'SIGGRAPH', 'entity': 'Conference'}, {'span': 'computer graphics', 'entity': 'Field'}, {'span': 'Symposium on Geometry Processing', 'entity': 'Conference'}]'

Example #10: Neuroevolution is commonly used as part of the reinforcement learning paradigm, and it can be contrasted with conventional deep learning techniques that use gradient descent on a neural network with a fixed topology.
Expected output: 'entities: [{'span': 'Neuroevolution', 'entity': 'Misc'}, {'span': 'reinforcement learning', 'entity': 'Field'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'neural network', 'entity': 'Algorithm'}]'

