Example #1: One can use the OSD algorithm to derive math O (\ sqrt { T }) / math regret bounds for the online version of Support vector machine for classification, which use the hinge loss math v _ t (w) = \ max \ { 0, 1 - y _ t (w \ cdot x _ t) \ } / math
Expected output: 'entities: [{'span': 'OSD algorithm', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'classification', 'entity': 'Task'}, {'span': 'hinge loss', 'entity': 'Metrics'}]'

Example #2: An autoencoder is a type of artificial neural network used to learn Feature learning in an unsupervised learning manner.
Expected output: 'entities: [{'span': 'autoencoder', 'entity': 'Algorithm'}, {'span': 'artificial neural network', 'entity': 'Algorithm'}, {'span': 'Feature learning', 'entity': 'Task'}, {'span': 'unsupervised learning', 'entity': 'Field'}]'

Example #3: To allow for multiple entities, a separate Hinge loss is computed for each capsule.
Expected output: 'entities: [{'span': 'Hinge loss', 'entity': 'Metrics'}]'

Example #4: A fast method for computing maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss ' work in 1935.
Expected output: 'entities: [{'span': 'maximum likelihood', 'entity': 'Metrics'}, {'span': 'probit model', 'entity': 'Algorithm'}, {'span': 'Ronald Fisher', 'entity': 'Researcher'}, {'span': 'Bliss', 'entity': 'Researcher'}]'

Example #5: If the signal is further ergodic, all sample paths exhibits the same time-average and thus mathR _ x ^ { n / T _ 0 } (\ tau) = \ widehat { R } _ x ^ { n / T _ 0 } (\ tau) / math in mean square error sense.
Expected output: 'entities: [{'span': 'mean square error', 'entity': 'Metrics'}]'

Example #6: If we use least squares to fit a function in the form of a hyperplane ŷ = a + β supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 ≤ i ≤ n / sub, we could then assess the fit using the mean squared error (MSE).
Expected output: 'entities: [{'span': 'least squares', 'entity': 'Algorithm'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #7: RapidMiner provides learning schemes, models and algorithms and can be extended using R and Python scripts. David Norris, Bloor Research, November 13, 2013.
Expected output: 'entities: [{'span': 'RapidMiner', 'entity': 'Product'}, {'span': 'R', 'entity': 'Programming Language'}, {'span': 'Python', 'entity': 'Programming Language'}, {'span': 'David Norris', 'entity': 'Researcher'}, {'span': 'Bloor Research', 'entity': 'Organisation'}]'

Example #8: , C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others uses local features like histogram of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.
Expected output: 'entities: [{'span': 'C. Papageorgiou', 'entity': 'Researcher'}, {'span': 'T. Poggio', 'entity': 'Researcher'}, {'span': 'Trainable Pedestrian Detection system', 'entity': 'Product'}, {'span': 'International Journal of Computer Vision', 'entity': 'Conference'}, {'span': 'IJCV', 'entity': 'Conference'}, {'span': 'histogram of oriented gradients', 'entity': 'Algorithm'}, {'span': 'N. Dalal', 'entity': 'Researcher'}, {'span': 'B. Triggs', 'entity': 'Researcher'}, {'span': 'Histograms of oriented gradients', 'entity': 'Algorithm'}, {'span': 'human detection', 'entity': 'Task'}, {'span': 'IEEE Computer Society Conference on Computer Vision and Pattern Recognition', 'entity': 'Conference'}, {'span': 'CVPR', 'entity': 'Conference'}]'

Example #9: Examples of supervised learning are Naive Bayes classifier, Support vector machine, mixtures of Gaussians, and network.
Expected output: 'entities: [{'span': 'supervised learning', 'entity': 'Field'}, {'span': 'Naive Bayes classifier', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'mixtures of Gaussians', 'entity': 'Algorithm'}, {'span': 'network', 'entity': 'Algorithm'}]'

Example #10: Geometry processing is a common research topic at SIGGRAPH, the premier computer graphics academic conference, and the main topic of the annual Symposium on Geometry Processing.
Expected output: 'entities: [{'span': 'Geometry processing', 'entity': 'Field'}, {'span': 'SIGGRAPH', 'entity': 'Conference'}, {'span': 'computer graphics', 'entity': 'Field'}, {'span': 'Symposium on Geometry Processing', 'entity': 'Conference'}]'

