Example #1: The sigmoid function s and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, these were released in a separate R package sigmoid, with the intention to enable more general use.
Expected output: 'entities: [{'span': 'sigmoid function', 'entity': 'Algorithm'}, {'span': 'R', 'entity': 'Programming Language'}, {'span': 'sigmoid', 'entity': 'Algorithm'}]'

Example #2: An autoencoder is a type of artificial neural network used to learn Feature learning in an unsupervised learning manner.
Expected output: 'entities: [{'span': 'autoencoder', 'entity': 'Algorithm'}, {'span': 'artificial neural network', 'entity': 'Algorithm'}, {'span': 'Feature learning', 'entity': 'Task'}, {'span': 'unsupervised learning', 'entity': 'Field'}]'

Example #3: If we use least squares to fit a function in the form of a hyperplane ŷ = a + β supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 ≤ i ≤ n / sub, we could then assess the fit using the mean squared error (MSE).
Expected output: 'entities: [{'span': 'least squares', 'entity': 'Algorithm'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #4: Sigmoid function Cross entropy loss is used for predicting K independent probability values in math 0,1 / math.
Expected output: 'entities: [{'span': 'Sigmoid function Cross entropy loss', 'entity': 'Metrics'}]'

Example #5: In digital signal processing and information theory, the normalized sinc function is commonly defined for by
Expected output: 'entities: [{'span': 'digital signal processing', 'entity': 'Field'}, {'span': 'information theory', 'entity': 'Field'}, {'span': 'normalized sinc function', 'entity': 'Algorithm'}]'

