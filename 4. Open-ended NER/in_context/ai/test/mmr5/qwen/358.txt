Example #1: The NIST metric is based on the BLEU metric, but with some alterations.
Expected output: 'entities: [{'span': 'NIST metric', 'entity': 'Metrics'}, {'span': 'BLEU metric', 'entity': 'Metrics'}]'

Example #2: , C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others uses local features like histogram of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.
Expected output: 'entities: [{'span': 'C. Papageorgiou', 'entity': 'Researcher'}, {'span': 'T. Poggio', 'entity': 'Researcher'}, {'span': 'Trainable Pedestrian Detection system', 'entity': 'Product'}, {'span': 'International Journal of Computer Vision', 'entity': 'Conference'}, {'span': 'IJCV', 'entity': 'Conference'}, {'span': 'histogram of oriented gradients', 'entity': 'Algorithm'}, {'span': 'N. Dalal', 'entity': 'Researcher'}, {'span': 'B. Triggs', 'entity': 'Researcher'}, {'span': 'Histograms of oriented gradients', 'entity': 'Algorithm'}, {'span': 'human detection', 'entity': 'Task'}, {'span': 'IEEE Computer Society Conference on Computer Vision and Pattern Recognition', 'entity': 'Conference'}, {'span': 'CVPR', 'entity': 'Conference'}]'

Example #3: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

Example #4: During the 1990s, encouraged by successes in speech recognition and speech synthesis, research began into speech translation with the development of the German Verbmobil project.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'speech translation', 'entity': 'Task'}, {'span': 'German', 'entity': 'Misc'}, {'span': 'Verbmobil project', 'entity': 'Misc'}]'

Example #5: As with BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentence s, the candidate translation string, and the reference translation string.
Expected output: 'entities: [{'span': 'BLEU', 'entity': 'Metrics'}]'

