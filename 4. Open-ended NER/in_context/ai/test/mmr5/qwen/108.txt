Example #1: As for the results, the C-HOG and R-HOG block descriptors perform comparably, with the C-HOG descriptors maintaining a slight advantage in the detection miss rate at fixed FALSE positive rate s across both data sets.
Expected output: 'entities: [{'span': 'C-HOG', 'entity': 'Algorithm'}, {'span': 'R-HOG', 'entity': 'Algorithm'}, {'span': 'C-HOG descriptors', 'entity': 'Algorithm'}, {'span': 'FALSE positive rate', 'entity': 'Metrics'}]'

Example #2: Sigmoid function Cross entropy loss is used for predicting K independent probability values in math 0,1 / math.
Expected output: 'entities: [{'span': 'Sigmoid function Cross entropy loss', 'entity': 'Metrics'}]'

Example #3: If the signal is further ergodic, all sample paths exhibits the same time-average and thus mathR _ x ^ { n / T _ 0 } (\ tau) = \ widehat { R } _ x ^ { n / T _ 0 } (\ tau) / math in mean square error sense.
Expected output: 'entities: [{'span': 'mean square error', 'entity': 'Metrics'}]'

Example #4: More recently, fictional representations of artificially intelligent robots in films such as A.I. Artificial Intelligence and Ex Machina and the 2016 TV adaptation of Westworld have engaged audience sympathy for the robots themselves.
Expected output: 'entities: [{'span': 'artificially intelligent robots', 'entity': 'Product'}, {'span': 'A.I. Artificial Intelligence', 'entity': 'Misc'}, {'span': 'Ex Machina', 'entity': 'Misc'}, {'span': 'Westworld', 'entity': 'Misc'}]'

Example #5: As with BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentence s, the candidate translation string, and the reference translation string.
Expected output: 'entities: [{'span': 'BLEU', 'entity': 'Metrics'}]'

