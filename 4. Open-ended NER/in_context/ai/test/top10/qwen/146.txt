Example #1: Sigmoid function Cross entropy loss is used for predicting K independent probability values in math 0,1 / math.
Expected output: 'entities: [{'span': 'Sigmoid function Cross entropy loss', 'entity': 'Metrics'}]'

Example #2: The NIST metric is based on the BLEU metric, but with some alterations.
Expected output: 'entities: [{'span': 'NIST metric', 'entity': 'Metrics'}, {'span': 'BLEU metric', 'entity': 'Metrics'}]'

Example #3: To allow for multiple entities, a separate Hinge loss is computed for each capsule.
Expected output: 'entities: [{'span': 'Hinge loss', 'entity': 'Metrics'}]'

Example #4: This math \ theta ^ { * } / math is normally estimated using a Maximum Likelihood (math \ theta ^ { * } = \ theta ^ { ML } / math) or Maximum A Posteriori (math \ theta ^ { * } = \ theta ^ { MAP } / math) procedure.
Expected output: 'entities: [{'span': 'Maximum Likelihood', 'entity': 'Algorithm'}, {'span': 'Maximum A Posteriori', 'entity': 'Algorithm'}, {'span': 'MAP', 'entity': 'Algorithm'}]'

Example #5: The most common way is using the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.
Expected output: 'entities: [{'span': 'ROUGE', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}]'

Example #6: Although used mainly by statisticians and other practitioners requiring an environment for statistical computation and software development, R can also operate as a general matrix calculation toolbox - with performance benchmarks comparable to GNU Octave or MATLAB.
Expected output: 'entities: [{'span': 'R', 'entity': 'Programming Language'}, {'span': 'GNU Octave', 'entity': 'Programming Language'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #7: The information retrieval metrics such as precision and recall or DCG are useful to assess the quality of a recommendation method.
Expected output: 'entities: [{'span': 'information retrieval', 'entity': 'Task'}, {'span': 'precision', 'entity': 'Metrics'}, {'span': 'recall', 'entity': 'Metrics'}, {'span': 'DCG', 'entity': 'Metrics'}]'

Example #8: Also in regression analysis, mean squared error, often referred to as mean squared prediction error or out-of-sample mean squared error, can refer to the mean value of the squared deviations of the predictions from the TRUE values, over an out-of-sample test space, generated by a model estimated over a particular sample space.
Expected output: 'entities: [{'span': 'regression analysis', 'entity': 'Task'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'mean squared prediction error', 'entity': 'Metrics'}, {'span': 'out-of-sample mean squared error', 'entity': 'Metrics'}, {'span': 'squared deviations', 'entity': 'Misc'}]'

Example #9: J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.
Expected output: 'entities: [{'span': 'J48', 'entity': 'Product'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'C4.5 algorithm', 'entity': 'Algorithm'}, {'span': 'Weka data mining tool', 'entity': 'Product'}]'

Example #10: If we use least squares to fit a function in the form of a hyperplane ŷ = a + β supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 ≤ i ≤ n / sub, we could then assess the fit using the mean squared error (MSE).
Expected output: 'entities: [{'span': 'least squares', 'entity': 'Algorithm'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

