Example #1: With the emergence of conversational assistants such as Apple's Siri, Amazon Alexa, Google Assistant, Microsoft Cortana, and Samsung's Bixby, Voice Portals can now be accessed through mobile devices and Far Field voice smart speakers such as the Amazon Echo and Google Home.
Expected output: 'entities: [{'span': "Apple's Siri", 'entity': 'Product'}, {'span': 'Amazon Alexa', 'entity': 'Product'}, {'span': 'Google Assistant', 'entity': 'Product'}, {'span': 'Microsoft Cortana', 'entity': 'Product'}, {'span': "Samsung's Bixby", 'entity': 'Product'}, {'span': 'Voice Portals', 'entity': 'Product'}, {'span': 'Far Field voice smart speakers', 'entity': 'Product'}, {'span': 'Amazon Echo', 'entity': 'Product'}, {'span': 'Google Home', 'entity': 'Product'}]'

Example #2: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #3: The speech synthesis is verging on being completely indistinguishable from a real human's voice with the 2016 introduction of the voice editing and generation software Adobe Voco, a prototype slated to be a part of the Adobe Creative Suite and DeepMind WaveNet, a prototype from Google.
Expected output: 'entities: [{'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'Adobe Voco', 'entity': 'Product'}, {'span': 'Adobe Creative Suite', 'entity': 'Product'}, {'span': 'DeepMind', 'entity': 'Organisation'}, {'span': 'WaveNet', 'entity': 'Product'}, {'span': 'Google', 'entity': 'Organisation'}]'

Example #4: The input is called speech recognition and the output is called speech synthesis.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #5: Modern Windows desktop systems can use SAPI 4 and SAPI 5 components to support speech synthesis and speech.
Expected output: 'entities: [{'span': 'Windows desktop systems', 'entity': 'Product'}, {'span': 'SAPI 4', 'entity': 'Product'}, {'span': 'SAPI 5', 'entity': 'Product'}, {'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'speech', 'entity': 'Task'}]'

Example #6: DeepFace is a deep learning facial recognition system created by a research group at Facebook.
Expected output: 'entities: [{'span': 'DeepFace', 'entity': 'Product'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'facial recognition', 'entity': 'Task'}, {'span': 'Facebook', 'entity': 'Organisation'}]'

Example #7: Some less widely spoken languages use the open-source eSpeak synthesizer for their speech; producing a robotic, awkward voice that may be difficult to understand.
Expected output: 'entities: [{'span': 'eSpeak synthesizer', 'entity': 'Product'}]'

Example #8: Voice user interfaces that interpret and manage conversational state are challenging to design due to the inherent difficulty of integrating complex natural language processing tasks like coreference resolution, named-entity recognition, information retrieval, and dialog management.
Expected output: 'entities: [{'span': 'Voice user interfaces', 'entity': 'Product'}, {'span': 'natural language processing', 'entity': 'Field'}, {'span': 'coreference resolution', 'entity': 'Task'}, {'span': 'named-entity recognition', 'entity': 'Task'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'dialog management', 'entity': 'Task'}]'

Example #9: The first attempt at end-to-end ASR was with Connectionist Temporal Classification (CTC) -based systems introduced by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto in 2014.
Expected output: 'entities: [{'span': 'end-to-end ASR', 'entity': 'Task'}, {'span': 'Connectionist Temporal Classification', 'entity': 'Algorithm'}, {'span': 'CTC', 'entity': 'Algorithm'}, {'span': 'Alex Graves', 'entity': 'Researcher'}, {'span': 'Google DeepMind', 'entity': 'Organisation'}, {'span': 'Navdeep Jaitly', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

Example #10: During the 1990s, encouraged by successes in speech recognition and speech synthesis, research began into speech translation with the development of the German Verbmobil project.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'speech translation', 'entity': 'Task'}, {'span': 'German', 'entity': 'Misc'}, {'span': 'Verbmobil project', 'entity': 'Misc'}]'

