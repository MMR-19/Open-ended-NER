Example #1: The NIST metric is based on the BLEU metric, but with some alterations.
Expected output: 'entities: [{'span': 'NIST metric', 'entity': 'Metrics'}, {'span': 'BLEU metric', 'entity': 'Metrics'}]'

Example #2: One of the metrics used in NIST ' s annual Document Understanding Conferences, in which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.
Expected output: 'entities: [{'span': "NIST ' s annual Document Understanding Conferences", 'entity': 'Conference'}, {'span': 'summarization', 'entity': 'Task'}, {'span': 'translation tasks', 'entity': 'Task'}, {'span': 'ROUGE metric', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}, {'span': 'Neural Information Processing Systems', 'entity': 'Conference'}, {'span': 'NIPS', 'entity': 'Conference'}, {'span': 'Montreal', 'entity': 'Location'}, {'span': 'Canada', 'entity': 'Country'}]'

Example #3: As with BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentence s, the candidate translation string, and the reference translation string.
Expected output: 'entities: [{'span': 'BLEU', 'entity': 'Metrics'}]'

Example #4: The most common way is using the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.
Expected output: 'entities: [{'span': 'ROUGE', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}]'

Example #5: The information retrieval metrics such as precision and recall or DCG are useful to assess the quality of a recommendation method.
Expected output: 'entities: [{'span': 'information retrieval', 'entity': 'Task'}, {'span': 'precision', 'entity': 'Metrics'}, {'span': 'recall', 'entity': 'Metrics'}, {'span': 'DCG', 'entity': 'Metrics'}]'

Example #6: Since the early 1990s, it has been recommended by several authorities, including the Audio Engineering Society that measurements of dynamic range be made with an audio signal present, which is then filtered out in the noise floor measurement used in determining dynamic range. This avoids questionable measurements based on the use of blank media, or muting circuits.
Expected output: 'entities: [{'span': 'Audio Engineering Society', 'entity': 'Organisation'}, {'span': 'audio signal', 'entity': 'Misc'}, {'span': 'noise floor measurement', 'entity': 'Metrics'}]'

Example #7: The 2004 SSIM paper has been cited over 20,000 times according to Google Scholar, It also received the IEEE Signal Processing Society Sustained Impact Award for 2016, indicative of a paper having an unusually high impact for at least 10 years following its publication.
Expected output: 'entities: [{'span': 'SSIM', 'entity': 'Metrics'}, {'span': 'Google Scholar', 'entity': 'Product'}, {'span': 'IEEE Signal Processing Society Sustained Impact Award', 'entity': 'Misc'}]'

Example #8: Also in regression analysis, mean squared error, often referred to as mean squared prediction error or out-of-sample mean squared error, can refer to the mean value of the squared deviations of the predictions from the TRUE values, over an out-of-sample test space, generated by a model estimated over a particular sample space.
Expected output: 'entities: [{'span': 'regression analysis', 'entity': 'Task'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'mean squared prediction error', 'entity': 'Metrics'}, {'span': 'out-of-sample mean squared error', 'entity': 'Metrics'}, {'span': 'squared deviations', 'entity': 'Misc'}]'

Example #9: Another technique particularly used for recurrent neural network s is the long short-term memory (LSTM) network of 1997 by Sepp Hochreiter & Jürgen Schmidhuber.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'long short-term memory', 'entity': 'Algorithm'}, {'span': 'LSTM', 'entity': 'Algorithm'}, {'span': 'Sepp Hochreiter', 'entity': 'Researcher'}, {'span': 'Jürgen Schmidhuber', 'entity': 'Researcher'}]'

Example #10: The National Science Foundation was an umbrella for the National Aeronautics and Space Administration (NASA), the US Department of Energy, the US Department of Commerce NIST, the US Department of Defense, Defense Advanced Research Projects Agency (DARPA), and the Office of Naval Research coordinated studies to inform strategic planners in their deliberations.
Expected output: 'entities: [{'span': 'National Science Foundation', 'entity': 'Organisation'}, {'span': 'National Aeronautics and Space Administration', 'entity': 'Organisation'}, {'span': 'NASA', 'entity': 'Organisation'}, {'span': 'US Department of Energy', 'entity': 'Organisation'}, {'span': 'US Department of Commerce NIST', 'entity': 'Organisation'}, {'span': 'US Department of Defense', 'entity': 'Organisation'}, {'span': 'Defense Advanced Research Projects Agency', 'entity': 'Organisation'}, {'span': 'DARPA', 'entity': 'Organisation'}, {'span': 'Office of Naval Research', 'entity': 'Organisation'}]'

