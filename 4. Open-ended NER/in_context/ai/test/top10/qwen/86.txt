Example #1: The sigmoid function s and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, these were released in a separate R package sigmoid, with the intention to enable more general use.
Expected output: 'entities: [{'span': 'sigmoid function', 'entity': 'Algorithm'}, {'span': 'R', 'entity': 'Programming Language'}, {'span': 'sigmoid', 'entity': 'Algorithm'}]'

Example #2: Sigmoid function Cross entropy loss is used for predicting K independent probability values in math 0,1 / math.
Expected output: 'entities: [{'span': 'Sigmoid function Cross entropy loss', 'entity': 'Metrics'}]'

Example #3: In digital signal processing and information theory, the normalized sinc function is commonly defined for by
Expected output: 'entities: [{'span': 'digital signal processing', 'entity': 'Field'}, {'span': 'information theory', 'entity': 'Field'}, {'span': 'normalized sinc function', 'entity': 'Algorithm'}]'

Example #4: To allow for multiple entities, a separate Hinge loss is computed for each capsule.
Expected output: 'entities: [{'span': 'Hinge loss', 'entity': 'Metrics'}]'

Example #5: Self-organizing maps differ from other artificial neural networks as they apply competitive learning as opposed to error-correction learning such as backpropagation with gradient descent), and in the sense that they use a neighborhood function to preserve the topological properties of the input space.
Expected output: 'entities: [{'span': 'artificial neural networks', 'entity': 'Algorithm'}, {'span': 'competitive learning', 'entity': 'Algorithm'}, {'span': 'error-correction learning', 'entity': 'Algorithm'}, {'span': 'backpropagation', 'entity': 'Algorithm'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'topological properties', 'entity': 'Misc'}]'

Example #6: or equivalently using DCG notation:
Expected output: 'entities: [{'span': 'DCG', 'entity': 'Metrics'}]'

Example #7: An autoencoder is a type of artificial neural network used to learn Feature learning in an unsupervised learning manner.
Expected output: 'entities: [{'span': 'autoencoder', 'entity': 'Algorithm'}, {'span': 'artificial neural network', 'entity': 'Algorithm'}, {'span': 'Feature learning', 'entity': 'Task'}, {'span': 'unsupervised learning', 'entity': 'Field'}]'

Example #8: Octave helps in solving linear and nonlinear problems numerically, and for performing other numerical experiments using a that is mostly compatible with MATLAB.
Expected output: 'entities: [{'span': 'Octave', 'entity': 'Product'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #9: Although used mainly by statisticians and other practitioners requiring an environment for statistical computation and software development, R can also operate as a general matrix calculation toolbox - with performance benchmarks comparable to GNU Octave or MATLAB.
Expected output: 'entities: [{'span': 'R', 'entity': 'Programming Language'}, {'span': 'GNU Octave', 'entity': 'Programming Language'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #10: The 2004 SSIM paper has been cited over 20,000 times according to Google Scholar, It also received the IEEE Signal Processing Society Sustained Impact Award for 2016, indicative of a paper having an unusually high impact for at least 10 years following its publication.
Expected output: 'entities: [{'span': 'SSIM', 'entity': 'Metrics'}, {'span': 'Google Scholar', 'entity': 'Product'}, {'span': 'IEEE Signal Processing Society Sustained Impact Award', 'entity': 'Misc'}]'

