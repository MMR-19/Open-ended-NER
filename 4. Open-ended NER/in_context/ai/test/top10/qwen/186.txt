Example #1: J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.
Expected output: 'entities: [{'span': 'J48', 'entity': 'Product'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'C4.5 algorithm', 'entity': 'Algorithm'}, {'span': 'Weka data mining tool', 'entity': 'Product'}]'

Example #2: RapidMiner provides learning schemes, models and algorithms and can be extended using R and Python scripts. David Norris, Bloor Research, November 13, 2013.
Expected output: 'entities: [{'span': 'RapidMiner', 'entity': 'Product'}, {'span': 'R', 'entity': 'Programming Language'}, {'span': 'Python', 'entity': 'Programming Language'}, {'span': 'David Norris', 'entity': 'Researcher'}, {'span': 'Bloor Research', 'entity': 'Organisation'}]'

Example #3: Although used mainly by statisticians and other practitioners requiring an environment for statistical computation and software development, R can also operate as a general matrix calculation toolbox - with performance benchmarks comparable to GNU Octave or MATLAB.
Expected output: 'entities: [{'span': 'R', 'entity': 'Programming Language'}, {'span': 'GNU Octave', 'entity': 'Programming Language'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #4: A fast method for computing maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss ' work in 1935.
Expected output: 'entities: [{'span': 'maximum likelihood', 'entity': 'Metrics'}, {'span': 'probit model', 'entity': 'Algorithm'}, {'span': 'Ronald Fisher', 'entity': 'Researcher'}, {'span': 'Bliss', 'entity': 'Researcher'}]'

Example #5: The sigmoid function s and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, these were released in a separate R package sigmoid, with the intention to enable more general use.
Expected output: 'entities: [{'span': 'sigmoid function', 'entity': 'Algorithm'}, {'span': 'R', 'entity': 'Programming Language'}, {'span': 'sigmoid', 'entity': 'Algorithm'}]'

Example #6: Another technique particularly used for recurrent neural network s is the long short-term memory (LSTM) network of 1997 by Sepp Hochreiter & Jürgen Schmidhuber.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'long short-term memory', 'entity': 'Algorithm'}, {'span': 'LSTM', 'entity': 'Algorithm'}, {'span': 'Sepp Hochreiter', 'entity': 'Researcher'}, {'span': 'Jürgen Schmidhuber', 'entity': 'Researcher'}]'

Example #7: The most common way is using the so-called ROUGE (Recall-Oriented Understudy for Gisting Evaluation) measure.
Expected output: 'entities: [{'span': 'ROUGE', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}]'

Example #8: The technique used in creating eigenfaces and using them for recognition is also used outside of face recognition: handwriting recognition, lip reading, voice recognition, sign language / hand gestures interpretation and medical imaging analysis.
Expected output: 'entities: [{'span': 'eigenfaces', 'entity': 'Misc'}, {'span': 'face recognition', 'entity': 'Task'}, {'span': 'handwriting recognition', 'entity': 'Task'}, {'span': 'lip reading', 'entity': 'Task'}, {'span': 'voice recognition', 'entity': 'Task'}, {'span': 'sign language', 'entity': 'Task'}, {'span': 'hand gestures interpretation', 'entity': 'Task'}, {'span': 'medical imaging analysis', 'entity': 'Field'}]'

Example #9: Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.
Expected output: 'entities: [{'span': 'unsupervised learning', 'entity': 'Field'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'cluster analysis', 'entity': 'Task'}]'

Example #10: Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'non-negative matrix factorization', 'entity': 'Algorithm'}, {'span': 'NMF', 'entity': 'Algorithm'}, {'span': 'pre-processing step', 'entity': 'Misc'}, {'span': 'K-NN', 'entity': 'Algorithm'}, {'span': 'feature vectors', 'entity': 'Misc'}]'

