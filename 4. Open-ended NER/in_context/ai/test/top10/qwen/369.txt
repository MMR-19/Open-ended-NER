Example #1: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #2: The task of recognizing named entities in text is Named Entity Recognition while the task of determining the identity of the named entities mentioned in text is called Entity Linking.
Expected output: 'entities: [{'span': 'recognizing named entities in text', 'entity': 'Task'}, {'span': 'Named Entity Recognition', 'entity': 'Task'}, {'span': 'Entity Linking', 'entity': 'Task'}]'

Example #3: or equivalently using DCG notation:
Expected output: 'entities: [{'span': 'DCG', 'entity': 'Metrics'}]'

Example #4: Since 2002, perceptron training has become popular in the field of natural language processing for such tasks as part-of-speech tagging and syntactic parsing (Collins, 2002).
Expected output: 'entities: [{'span': 'natural language processing', 'entity': 'Field'}, {'span': 'part-of-speech tagging', 'entity': 'Task'}, {'span': 'syntactic parsing', 'entity': 'Task'}, {'span': 'Collins', 'entity': 'Researcher'}]'

Example #5: The input is called speech recognition and the output is called speech synthesis.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #6: The NIST metric is based on the BLEU metric, but with some alterations.
Expected output: 'entities: [{'span': 'NIST metric', 'entity': 'Metrics'}, {'span': 'BLEU metric', 'entity': 'Metrics'}]'

Example #7: Octave helps in solving linear and nonlinear problems numerically, and for performing other numerical experiments using a that is mostly compatible with MATLAB.
Expected output: 'entities: [{'span': 'Octave', 'entity': 'Product'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #8: Grammar checkers are most often implemented as a feature of a larger program, such as a word processor, but are also available as a stand-alone application that can be activated from within programs that work with editable text.
Expected output: 'entities: [{'span': 'Grammar checkers', 'entity': 'Product'}, {'span': 'word processor', 'entity': 'Product'}]'

Example #9: An autoencoder is a type of artificial neural network used to learn Feature learning in an unsupervised learning manner.
Expected output: 'entities: [{'span': 'autoencoder', 'entity': 'Algorithm'}, {'span': 'artificial neural network', 'entity': 'Algorithm'}, {'span': 'Feature learning', 'entity': 'Task'}, {'span': 'unsupervised learning', 'entity': 'Field'}]'

Example #10: In the late 1980s, two Netherlands universities, University of Groningen and University of Twente, jointly began a project called Knowledge Graphs, which are semantic networks but with the added constraint that edges are restricted to be from a limited set of possible relations, to facilitate algebras on the graph.
Expected output: 'entities: [{'span': 'Netherlands', 'entity': 'Country'}, {'span': 'University of Groningen', 'entity': 'University'}, {'span': 'University of Twente', 'entity': 'University'}, {'span': 'Knowledge Graphs', 'entity': 'Product'}, {'span': 'semantic networks', 'entity': 'Algorithm'}]'

