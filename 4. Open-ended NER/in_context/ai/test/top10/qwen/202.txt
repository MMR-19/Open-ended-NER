Example #1: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #2: The input is called speech recognition and the output is called speech synthesis.
Expected output: 'entities: [{'span': 'speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #3: The first attempt at end-to-end ASR was with Connectionist Temporal Classification (CTC) -based systems introduced by Alex Graves of Google DeepMind and Navdeep Jaitly of the University of Toronto in 2014.
Expected output: 'entities: [{'span': 'end-to-end ASR', 'entity': 'Task'}, {'span': 'Connectionist Temporal Classification', 'entity': 'Algorithm'}, {'span': 'CTC', 'entity': 'Algorithm'}, {'span': 'Alex Graves', 'entity': 'Researcher'}, {'span': 'Google DeepMind', 'entity': 'Organisation'}, {'span': 'Navdeep Jaitly', 'entity': 'Researcher'}, {'span': 'University of Toronto', 'entity': 'University'}]'

Example #4: Popular recognition algorithms include principal component analysis using eigenface s, linear discriminant analysis, Elastic matching using the Fisherface algorithm, the hidden Markov model, the multilinear subspace learning using tensor representation, and the neuronal motivated dynamic link matching.
Expected output: 'entities: [{'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'eigenface', 'entity': 'Misc'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'Elastic matching', 'entity': 'Algorithm'}, {'span': 'Fisherface algorithm', 'entity': 'Algorithm'}, {'span': 'hidden Markov model', 'entity': 'Algorithm'}, {'span': 'multilinear subspace learning', 'entity': 'Algorithm'}, {'span': 'tensor representation', 'entity': 'Misc'}, {'span': 'dynamic link matching', 'entity': 'Algorithm'}]'

Example #5: An autoencoder is a type of artificial neural network used to learn Feature learning in an unsupervised learning manner.
Expected output: 'entities: [{'span': 'autoencoder', 'entity': 'Algorithm'}, {'span': 'artificial neural network', 'entity': 'Algorithm'}, {'span': 'Feature learning', 'entity': 'Task'}, {'span': 'unsupervised learning', 'entity': 'Field'}]'

Example #6: The speech synthesis is verging on being completely indistinguishable from a real human's voice with the 2016 introduction of the voice editing and generation software Adobe Voco, a prototype slated to be a part of the Adobe Creative Suite and DeepMind WaveNet, a prototype from Google.
Expected output: 'entities: [{'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'Adobe Voco', 'entity': 'Product'}, {'span': 'Adobe Creative Suite', 'entity': 'Product'}, {'span': 'DeepMind', 'entity': 'Organisation'}, {'span': 'WaveNet', 'entity': 'Product'}, {'span': 'Google', 'entity': 'Organisation'}]'

Example #7: Modern Windows desktop systems can use SAPI 4 and SAPI 5 components to support speech synthesis and speech.
Expected output: 'entities: [{'span': 'Windows desktop systems', 'entity': 'Product'}, {'span': 'SAPI 4', 'entity': 'Product'}, {'span': 'SAPI 5', 'entity': 'Product'}, {'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'speech', 'entity': 'Task'}]'

Example #8: Some less widely spoken languages use the open-source eSpeak synthesizer for their speech; producing a robotic, awkward voice that may be difficult to understand.
Expected output: 'entities: [{'span': 'eSpeak synthesizer', 'entity': 'Product'}]'

Example #9: Artificial neural networks are computational models that excel at machine learning and pattern recognition.
Expected output: 'entities: [{'span': 'Artificial neural networks', 'entity': 'Algorithm'}, {'span': 'machine learning', 'entity': 'Field'}, {'span': 'pattern recognition', 'entity': 'Field'}]'

Example #10: The technique used in creating eigenfaces and using them for recognition is also used outside of face recognition: handwriting recognition, lip reading, voice recognition, sign language / hand gestures interpretation and medical imaging analysis.
Expected output: 'entities: [{'span': 'eigenfaces', 'entity': 'Misc'}, {'span': 'face recognition', 'entity': 'Task'}, {'span': 'handwriting recognition', 'entity': 'Task'}, {'span': 'lip reading', 'entity': 'Task'}, {'span': 'voice recognition', 'entity': 'Task'}, {'span': 'sign language', 'entity': 'Task'}, {'span': 'hand gestures interpretation', 'entity': 'Task'}, {'span': 'medical imaging analysis', 'entity': 'Field'}]'

