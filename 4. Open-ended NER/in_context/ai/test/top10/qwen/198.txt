Example #1: Artificial neural networks are computational models that excel at machine learning and pattern recognition.
Expected output: 'entities: [{'span': 'Artificial neural networks', 'entity': 'Algorithm'}, {'span': 'machine learning', 'entity': 'Field'}, {'span': 'pattern recognition', 'entity': 'Field'}]'

Example #2: An autoencoder is a type of artificial neural network used to learn Feature learning in an unsupervised learning manner.
Expected output: 'entities: [{'span': 'autoencoder', 'entity': 'Algorithm'}, {'span': 'artificial neural network', 'entity': 'Algorithm'}, {'span': 'Feature learning', 'entity': 'Task'}, {'span': 'unsupervised learning', 'entity': 'Field'}]'

Example #3: The technique used in creating eigenfaces and using them for recognition is also used outside of face recognition: handwriting recognition, lip reading, voice recognition, sign language / hand gestures interpretation and medical imaging analysis.
Expected output: 'entities: [{'span': 'eigenfaces', 'entity': 'Misc'}, {'span': 'face recognition', 'entity': 'Task'}, {'span': 'handwriting recognition', 'entity': 'Task'}, {'span': 'lip reading', 'entity': 'Task'}, {'span': 'voice recognition', 'entity': 'Task'}, {'span': 'sign language', 'entity': 'Task'}, {'span': 'hand gestures interpretation', 'entity': 'Task'}, {'span': 'medical imaging analysis', 'entity': 'Field'}]'

Example #4: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #5: Since 2002, perceptron training has become popular in the field of natural language processing for such tasks as part-of-speech tagging and syntactic parsing (Collins, 2002).
Expected output: 'entities: [{'span': 'natural language processing', 'entity': 'Field'}, {'span': 'part-of-speech tagging', 'entity': 'Task'}, {'span': 'syntactic parsing', 'entity': 'Task'}, {'span': 'Collins', 'entity': 'Researcher'}]'

Example #6: Between 2009 and 2012, the recurrent neural network s and deep feedforward neural network s developed in the research group of Jürgen Schmidhuber at the Swiss AI Lab IDSIA have won eight international competitions in pattern recognition and machine learning.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'deep feedforward neural network', 'entity': 'Algorithm'}, {'span': 'Jürgen Schmidhuber', 'entity': 'Researcher'}, {'span': 'Swiss AI Lab IDSIA', 'entity': 'Organisation'}, {'span': 'pattern recognition', 'entity': 'Field'}, {'span': 'machine learning', 'entity': 'Field'}]'

Example #7: Applications include object recognition, robotic mapping and navigation, image stitching, 3D modeling, gesture recognition, video tracking, individual identification of wildlife and match moving.
Expected output: 'entities: [{'span': 'object recognition', 'entity': 'Task'}, {'span': 'robotic mapping', 'entity': 'Task'}, {'span': 'navigation', 'entity': 'Task'}, {'span': 'image stitching', 'entity': 'Task'}, {'span': '3D modeling', 'entity': 'Task'}, {'span': 'gesture recognition', 'entity': 'Task'}, {'span': 'video tracking', 'entity': 'Task'}, {'span': 'individual identification of wildlife', 'entity': 'Task'}, {'span': 'match moving', 'entity': 'Task'}]'

Example #8: Examples of supervised learning are Naive Bayes classifier, Support vector machine, mixtures of Gaussians, and network.
Expected output: 'entities: [{'span': 'supervised learning', 'entity': 'Field'}, {'span': 'Naive Bayes classifier', 'entity': 'Algorithm'}, {'span': 'Support vector machine', 'entity': 'Algorithm'}, {'span': 'mixtures of Gaussians', 'entity': 'Algorithm'}, {'span': 'network', 'entity': 'Algorithm'}]'

Example #9: Self-organizing maps differ from other artificial neural networks as they apply competitive learning as opposed to error-correction learning such as backpropagation with gradient descent), and in the sense that they use a neighborhood function to preserve the topological properties of the input space.
Expected output: 'entities: [{'span': 'artificial neural networks', 'entity': 'Algorithm'}, {'span': 'competitive learning', 'entity': 'Algorithm'}, {'span': 'error-correction learning', 'entity': 'Algorithm'}, {'span': 'backpropagation', 'entity': 'Algorithm'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'topological properties', 'entity': 'Misc'}]'

Example #10: Over the past decade, PCNNs have been used in a variety of image processing applications, including: image segmentation, feature generation, face extraction, motion detection, region growing, and noise reduction.
Expected output: 'entities: [{'span': 'PCNNs', 'entity': 'Product'}, {'span': 'image processing', 'entity': 'Field'}, {'span': 'image segmentation', 'entity': 'Task'}, {'span': 'feature generation', 'entity': 'Task'}, {'span': 'face extraction', 'entity': 'Task'}, {'span': 'motion detection', 'entity': 'Task'}, {'span': 'region growing', 'entity': 'Task'}, {'span': 'noise reduction', 'entity': 'Task'}]'

