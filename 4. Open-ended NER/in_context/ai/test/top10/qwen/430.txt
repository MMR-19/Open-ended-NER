Example #1: This math \ theta ^ { * } / math is normally estimated using a Maximum Likelihood (math \ theta ^ { * } = \ theta ^ { ML } / math) or Maximum A Posteriori (math \ theta ^ { * } = \ theta ^ { MAP } / math) procedure.
Expected output: 'entities: [{'span': 'Maximum Likelihood', 'entity': 'Algorithm'}, {'span': 'Maximum A Posteriori', 'entity': 'Algorithm'}, {'span': 'MAP', 'entity': 'Algorithm'}]'

Example #2: The parameters β are typically estimated by maximum likelihood.
Expected output: 'entities: [{'span': 'maximum likelihood', 'entity': 'Metrics'}]'

Example #3: A fast method for computing maximum likelihood estimates for the probit model was proposed by Ronald Fisher as an appendix to Bliss ' work in 1935.
Expected output: 'entities: [{'span': 'maximum likelihood', 'entity': 'Metrics'}, {'span': 'probit model', 'entity': 'Algorithm'}, {'span': 'Ronald Fisher', 'entity': 'Researcher'}, {'span': 'Bliss', 'entity': 'Researcher'}]'

Example #4: Sigmoid function Cross entropy loss is used for predicting K independent probability values in math 0,1 / math.
Expected output: 'entities: [{'span': 'Sigmoid function Cross entropy loss', 'entity': 'Metrics'}]'

Example #5: If the signal is further ergodic, all sample paths exhibits the same time-average and thus mathR _ x ^ { n / T _ 0 } (\ tau) = \ widehat { R } _ x ^ { n / T _ 0 } (\ tau) / math in mean square error sense.
Expected output: 'entities: [{'span': 'mean square error', 'entity': 'Metrics'}]'

Example #6: Also in regression analysis, mean squared error, often referred to as mean squared prediction error or out-of-sample mean squared error, can refer to the mean value of the squared deviations of the predictions from the TRUE values, over an out-of-sample test space, generated by a model estimated over a particular sample space.
Expected output: 'entities: [{'span': 'regression analysis', 'entity': 'Task'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'mean squared prediction error', 'entity': 'Metrics'}, {'span': 'out-of-sample mean squared error', 'entity': 'Metrics'}, {'span': 'squared deviations', 'entity': 'Misc'}]'

Example #7: A number of groups and companies are researching pose estimation, including groups at Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, the University of California, San Diego, the University of Toronto, the École Centrale Paris, ETH Zurich, National University of Sciences and Technology (NUST), and the University of California, Irvine.
Expected output: 'entities: [{'span': 'pose estimation', 'entity': 'Task'}, {'span': 'Brown University', 'entity': 'University'}, {'span': 'Carnegie Mellon University', 'entity': 'University'}, {'span': 'MPI Saarbruecken', 'entity': 'University'}, {'span': 'Stanford University', 'entity': 'University'}, {'span': 'University of California, San Diego', 'entity': 'University'}, {'span': 'University of Toronto', 'entity': 'University'}, {'span': 'École Centrale Paris', 'entity': 'University'}, {'span': 'ETH Zurich', 'entity': 'University'}, {'span': 'National University of Sciences and Technology', 'entity': 'University'}, {'span': 'NUST', 'entity': 'University'}, {'span': 'University of California, Irvine', 'entity': 'University'}]'

Example #8: If we use least squares to fit a function in the form of a hyperplane ŷ = a + β supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 ≤ i ≤ n / sub, we could then assess the fit using the mean squared error (MSE).
Expected output: 'entities: [{'span': 'least squares', 'entity': 'Algorithm'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #9: Octave helps in solving linear and nonlinear problems numerically, and for performing other numerical experiments using a that is mostly compatible with MATLAB.
Expected output: 'entities: [{'span': 'Octave', 'entity': 'Product'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #10: In digital signal processing and information theory, the normalized sinc function is commonly defined for by
Expected output: 'entities: [{'span': 'digital signal processing', 'entity': 'Field'}, {'span': 'information theory', 'entity': 'Field'}, {'span': 'normalized sinc function', 'entity': 'Algorithm'}]'

