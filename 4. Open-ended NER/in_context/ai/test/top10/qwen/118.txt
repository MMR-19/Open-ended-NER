Example #1: An optimal value for math \ alpha / math can be found by using a line search algorithm, that is, the magnitude of math \ alpha / math is determined by finding the value that minimizes S, usually using a line search in the interval math0 \ alpha 1 / math or a backtracking line search such as Armijo-line search.
Expected output: 'entities: [{'span': 'line search algorithm', 'entity': 'Algorithm'}, {'span': 'line search', 'entity': 'Algorithm'}, {'span': 'backtracking line search', 'entity': 'Algorithm'}, {'span': 'Armijo-line search', 'entity': 'Algorithm'}]'

Example #2: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

Example #3: Octave helps in solving linear and nonlinear problems numerically, and for performing other numerical experiments using a that is mostly compatible with MATLAB.
Expected output: 'entities: [{'span': 'Octave', 'entity': 'Product'}, {'span': 'MATLAB', 'entity': 'Product'}]'

Example #4: Applications include object recognition, robotic mapping and navigation, image stitching, 3D modeling, gesture recognition, video tracking, individual identification of wildlife and match moving.
Expected output: 'entities: [{'span': 'object recognition', 'entity': 'Task'}, {'span': 'robotic mapping', 'entity': 'Task'}, {'span': 'navigation', 'entity': 'Task'}, {'span': 'image stitching', 'entity': 'Task'}, {'span': '3D modeling', 'entity': 'Task'}, {'span': 'gesture recognition', 'entity': 'Task'}, {'span': 'video tracking', 'entity': 'Task'}, {'span': 'individual identification of wildlife', 'entity': 'Task'}, {'span': 'match moving', 'entity': 'Task'}]'

Example #5: Artificial neural networks are computational models that excel at machine learning and pattern recognition.
Expected output: 'entities: [{'span': 'Artificial neural networks', 'entity': 'Algorithm'}, {'span': 'machine learning', 'entity': 'Field'}, {'span': 'pattern recognition', 'entity': 'Field'}]'

Example #6: A number of groups and companies are researching pose estimation, including groups at Brown University, Carnegie Mellon University, MPI Saarbruecken, Stanford University, the University of California, San Diego, the University of Toronto, the École Centrale Paris, ETH Zurich, National University of Sciences and Technology (NUST), and the University of California, Irvine.
Expected output: 'entities: [{'span': 'pose estimation', 'entity': 'Task'}, {'span': 'Brown University', 'entity': 'University'}, {'span': 'Carnegie Mellon University', 'entity': 'University'}, {'span': 'MPI Saarbruecken', 'entity': 'University'}, {'span': 'Stanford University', 'entity': 'University'}, {'span': 'University of California, San Diego', 'entity': 'University'}, {'span': 'University of Toronto', 'entity': 'University'}, {'span': 'École Centrale Paris', 'entity': 'University'}, {'span': 'ETH Zurich', 'entity': 'University'}, {'span': 'National University of Sciences and Technology', 'entity': 'University'}, {'span': 'NUST', 'entity': 'University'}, {'span': 'University of California, Irvine', 'entity': 'University'}]'

Example #7: Speech recognition and speech synthesis deal with how spoken language can be understood or created using computers.
Expected output: 'entities: [{'span': 'Speech recognition', 'entity': 'Task'}, {'span': 'speech synthesis', 'entity': 'Task'}]'

Example #8: Self-organizing maps differ from other artificial neural networks as they apply competitive learning as opposed to error-correction learning such as backpropagation with gradient descent), and in the sense that they use a neighborhood function to preserve the topological properties of the input space.
Expected output: 'entities: [{'span': 'artificial neural networks', 'entity': 'Algorithm'}, {'span': 'competitive learning', 'entity': 'Algorithm'}, {'span': 'error-correction learning', 'entity': 'Algorithm'}, {'span': 'backpropagation', 'entity': 'Algorithm'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'topological properties', 'entity': 'Misc'}]'

Example #9: Popular recognition algorithms include principal component analysis using eigenface s, linear discriminant analysis, Elastic matching using the Fisherface algorithm, the hidden Markov model, the multilinear subspace learning using tensor representation, and the neuronal motivated dynamic link matching.
Expected output: 'entities: [{'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'eigenface', 'entity': 'Misc'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'Elastic matching', 'entity': 'Algorithm'}, {'span': 'Fisherface algorithm', 'entity': 'Algorithm'}, {'span': 'hidden Markov model', 'entity': 'Algorithm'}, {'span': 'multilinear subspace learning', 'entity': 'Algorithm'}, {'span': 'tensor representation', 'entity': 'Misc'}, {'span': 'dynamic link matching', 'entity': 'Algorithm'}]'

Example #10: Linear-fractional programming (LFP) is a generalization of linear programming (LP).
Expected output: 'entities: [{'span': 'Linear-fractional programming', 'entity': 'Algorithm'}, {'span': 'LFP', 'entity': 'Algorithm'}, {'span': 'linear programming', 'entity': 'Algorithm'}, {'span': 'LP', 'entity': 'Algorithm'}]'

