Example #1: The sigmoid function s and derivatives used in the package were originally included in the package, from version 0.8.0 onwards, these were released in a separate R package sigmoid, with the intention to enable more general use.
Expected output: 'entities: [{'span': 'sigmoid function', 'entity': 'Algorithm'}, {'span': 'R', 'entity': 'Programming Language'}, {'span': 'sigmoid', 'entity': 'Algorithm'}]'

Example #2: Another technique particularly used for recurrent neural network s is the long short-term memory (LSTM) network of 1997 by Sepp Hochreiter & Jürgen Schmidhuber.
Expected output: 'entities: [{'span': 'recurrent neural network', 'entity': 'Algorithm'}, {'span': 'long short-term memory', 'entity': 'Algorithm'}, {'span': 'LSTM', 'entity': 'Algorithm'}, {'span': 'Sepp Hochreiter', 'entity': 'Researcher'}, {'span': 'Jürgen Schmidhuber', 'entity': 'Researcher'}]'

Example #3: Self-organizing maps differ from other artificial neural networks as they apply competitive learning as opposed to error-correction learning such as backpropagation with gradient descent), and in the sense that they use a neighborhood function to preserve the topological properties of the input space.
Expected output: 'entities: [{'span': 'artificial neural networks', 'entity': 'Algorithm'}, {'span': 'competitive learning', 'entity': 'Algorithm'}, {'span': 'error-correction learning', 'entity': 'Algorithm'}, {'span': 'backpropagation', 'entity': 'Algorithm'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'topological properties', 'entity': 'Misc'}]'

Example #4: If we use least squares to fit a function in the form of a hyperplane ŷ = a + β supT / sup x to the data (x sub i / sub, y sub i / sub) sub 1 ≤ i ≤ n / sub, we could then assess the fit using the mean squared error (MSE).
Expected output: 'entities: [{'span': 'least squares', 'entity': 'Algorithm'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #5: The speech synthesis is verging on being completely indistinguishable from a real human's voice with the 2016 introduction of the voice editing and generation software Adobe Voco, a prototype slated to be a part of the Adobe Creative Suite and DeepMind WaveNet, a prototype from Google.
Expected output: 'entities: [{'span': 'speech synthesis', 'entity': 'Task'}, {'span': 'Adobe Voco', 'entity': 'Product'}, {'span': 'Adobe Creative Suite', 'entity': 'Product'}, {'span': 'DeepMind', 'entity': 'Organisation'}, {'span': 'WaveNet', 'entity': 'Product'}, {'span': 'Google', 'entity': 'Organisation'}]'

Example #6: The task of recognizing named entities in text is Named Entity Recognition while the task of determining the identity of the named entities mentioned in text is called Entity Linking.
Expected output: 'entities: [{'span': 'recognizing named entities in text', 'entity': 'Task'}, {'span': 'Named Entity Recognition', 'entity': 'Task'}, {'span': 'Entity Linking', 'entity': 'Task'}]'

Example #7: An optimal value for math \ alpha / math can be found by using a line search algorithm, that is, the magnitude of math \ alpha / math is determined by finding the value that minimizes S, usually using a line search in the interval math0 \ alpha 1 / math or a backtracking line search such as Armijo-line search.
Expected output: 'entities: [{'span': 'line search algorithm', 'entity': 'Algorithm'}, {'span': 'line search', 'entity': 'Algorithm'}, {'span': 'backtracking line search', 'entity': 'Algorithm'}, {'span': 'Armijo-line search', 'entity': 'Algorithm'}]'

Example #8: J48 is an open source Java implementation of the C4.5 algorithm in the Weka data mining tool.
Expected output: 'entities: [{'span': 'J48', 'entity': 'Product'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'C4.5 algorithm', 'entity': 'Algorithm'}, {'span': 'Weka data mining tool', 'entity': 'Product'}]'

Example #9: Neuroevolution is commonly used as part of the reinforcement learning paradigm, and it can be contrasted with conventional deep learning techniques that use gradient descent on a neural network with a fixed topology.
Expected output: 'entities: [{'span': 'Neuroevolution', 'entity': 'Misc'}, {'span': 'reinforcement learning', 'entity': 'Field'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'neural network', 'entity': 'Algorithm'}]'

Example #10: One of the metrics used in NIST ' s annual Document Understanding Conferences, in which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.
Expected output: 'entities: [{'span': "NIST ' s annual Document Understanding Conferences", 'entity': 'Conference'}, {'span': 'summarization', 'entity': 'Task'}, {'span': 'translation tasks', 'entity': 'Task'}, {'span': 'ROUGE metric', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}, {'span': 'Neural Information Processing Systems', 'entity': 'Conference'}, {'span': 'NIPS', 'entity': 'Conference'}, {'span': 'Montreal', 'entity': 'Location'}, {'span': 'Canada', 'entity': 'Country'}]'

