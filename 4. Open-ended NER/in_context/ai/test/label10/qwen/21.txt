Example #1: Neuroevolution is commonly used as part of the reinforcement learning paradigm, and it can be contrasted with conventional deep learning techniques that use gradient descent on a neural network with a fixed topology.
Expected output: 'entities: [{'span': 'Neuroevolution', 'entity': 'Misc'}, {'span': 'reinforcement learning', 'entity': 'Field'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'neural network', 'entity': 'Algorithm'}]'

Example #2: An optimal value for math \ alpha / math can be found by using a line search algorithm, that is, the magnitude of math \ alpha / math is determined by finding the value that minimizes S, usually using a line search in the interval math0 \ alpha 1 / math or a backtracking line search such as Armijo-line search.
Expected output: 'entities: [{'span': 'line search algorithm', 'entity': 'Algorithm'}, {'span': 'line search', 'entity': 'Algorithm'}, {'span': 'backtracking line search', 'entity': 'Algorithm'}, {'span': 'Armijo-line search', 'entity': 'Algorithm'}]'

Example #3: He discusses Breadth-first search and Depth-first search techniques, but eventually concludes that the results represent expert system s that incarnate a lot of technical knowledge but don 't shine much light on the mental processes that humans use to solve such puzzles.
Expected output: 'entities: [{'span': 'Breadth-first search', 'entity': 'Algorithm'}, {'span': 'Depth-first search', 'entity': 'Algorithm'}, {'span': 'expert system', 'entity': 'Product'}]'

Example #4: Geometry processing is a common research topic at SIGGRAPH, the premier computer graphics academic conference, and the main topic of the annual Symposium on Geometry Processing.
Expected output: 'entities: [{'span': 'Geometry processing', 'entity': 'Field'}, {'span': 'SIGGRAPH', 'entity': 'Conference'}, {'span': 'computer graphics', 'entity': 'Field'}, {'span': 'Symposium on Geometry Processing', 'entity': 'Conference'}]'

Example #5: Since the early 1990s, it has been recommended by several authorities, including the Audio Engineering Society that measurements of dynamic range be made with an audio signal present, which is then filtered out in the noise floor measurement used in determining dynamic range. This avoids questionable measurements based on the use of blank media, or muting circuits.
Expected output: 'entities: [{'span': 'Audio Engineering Society', 'entity': 'Organisation'}, {'span': 'audio signal', 'entity': 'Misc'}, {'span': 'noise floor measurement', 'entity': 'Metrics'}]'

Example #6: Linear predictive coding (LPC), a form of speech coding, began development with the work Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.
Expected output: 'entities: [{'span': 'Linear predictive coding', 'entity': 'Algorithm'}, {'span': 'LPC', 'entity': 'Algorithm'}, {'span': 'speech coding', 'entity': 'Task'}, {'span': 'Fumitada Itakura', 'entity': 'Researcher'}, {'span': 'Nagoya University', 'entity': 'University'}, {'span': 'Shuzo Saito', 'entity': 'Researcher'}, {'span': 'Nippon Telegraph and Telephone', 'entity': 'University'}, {'span': 'NTT', 'entity': 'University'}]'

Example #7: Since 2002, perceptron training has become popular in the field of natural language processing for such tasks as part-of-speech tagging and syntactic parsing (Collins, 2002).
Expected output: 'entities: [{'span': 'natural language processing', 'entity': 'Field'}, {'span': 'part-of-speech tagging', 'entity': 'Task'}, {'span': 'syntactic parsing', 'entity': 'Task'}, {'span': 'Collins', 'entity': 'Researcher'}]'

Example #8: Beginning at the 2019 Toronto International Film Festival, films may now be restricted from screening at Scotiabank Theatre Toronto - one of the festival's main venues - and screened elsewhere (such as TIFF Bell Lightbox and other local cinemas) if distributed by a service such as Netflix.
Expected output: 'entities: [{'span': '2019 Toronto International Film Festival', 'entity': 'Misc'}, {'span': 'Scotiabank Theatre Toronto', 'entity': 'Location'}, {'span': 'TIFF Bell Lightbox', 'entity': 'Location'}, {'span': 'Netflix', 'entity': 'Organisation'}]'

Example #9: Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'non-negative matrix factorization', 'entity': 'Algorithm'}, {'span': 'NMF', 'entity': 'Algorithm'}, {'span': 'pre-processing step', 'entity': 'Misc'}, {'span': 'K-NN', 'entity': 'Algorithm'}, {'span': 'feature vectors', 'entity': 'Misc'}]'

Example #10: Feature extraction and dimension reduction can be combined in one step using Principal Component Analysis (PCA), linear discriminant analysis (LDA), or canonical correlation analysis (CCA) techniques as a pre-processing step, followed by clustering by k -NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'Principal Component Analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'pre-processing', 'entity': 'Misc'}, {'span': 'k -NN', 'entity': 'Algorithm'}]'

