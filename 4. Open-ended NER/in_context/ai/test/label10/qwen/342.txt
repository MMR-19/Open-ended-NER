Example #1: tity contains a collection of visualization tools and algorithms for data analysis and predictive modeling, together with graphical user interfaces for easy access to these functions. but the more recent fully Java -based version (Weka 3), for which development started in 1997, is now used in many different application areas, in particular for educational purposes and research.
Expected output: 'entities: [{'span': 'tity', 'entity': 'Product'}, {'span': 'data analysis', 'entity': 'Field'}, {'span': 'predictive modeling', 'entity': 'Task'}, {'span': 'graphical user interfaces', 'entity': 'Misc'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'Weka 3', 'entity': 'Product'}]'

Example #2: Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'non-negative matrix factorization', 'entity': 'Algorithm'}, {'span': 'NMF', 'entity': 'Algorithm'}, {'span': 'pre-processing step', 'entity': 'Misc'}, {'span': 'K-NN', 'entity': 'Algorithm'}, {'span': 'feature vectors', 'entity': 'Misc'}]'

Example #3: Feature extraction and dimension reduction can be combined in one step using Principal Component Analysis (PCA), linear discriminant analysis (LDA), or canonical correlation analysis (CCA) techniques as a pre-processing step, followed by clustering by k -NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'Principal Component Analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'pre-processing', 'entity': 'Misc'}, {'span': 'k -NN', 'entity': 'Algorithm'}]'

Example #4: Popular approaches of opinion-based recommender system utilize various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.
Expected output: 'entities: [{'span': 'opinion-based recommender system', 'entity': 'Product'}, {'span': 'text mining', 'entity': 'Field'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'sentiment analysis', 'entity': 'Task'}, {'span': 'Multimodal sentiment analysis', 'entity': 'Task'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'X.Y. Feng', 'entity': 'Researcher'}, {'span': 'H. Zhang', 'entity': 'Researcher'}, {'span': 'Y.J. Ren', 'entity': 'Researcher'}, {'span': 'P.H. Shang', 'entity': 'Researcher'}, {'span': 'Y. Zhu', 'entity': 'Researcher'}, {'span': 'Y.C. Liang', 'entity': 'Researcher'}, {'span': 'R.C. Guan', 'entity': 'Researcher'}, {'span': 'D. Xu', 'entity': 'Researcher'}]'

Example #5: 59, pp. 2547-2553, Oct. 2011 In one dimensional polynomial-based memory (or memoryless) DPD, in order to solve for the digital pre-distorter polynomials coefficients and minimize the mean squared error (MSE), the distorted output of the nonlinear system must be over-sampled at a rate that enables the capture of the nonlinear products of the order of the digital pre-distorter.
Expected output: 'entities: [{'span': 'one dimensional polynomial-based memory', 'entity': 'Misc'}, {'span': 'DPD', 'entity': 'Misc'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #6: Haralick is a Fellow of IEEE for his contributions in computer vision and image processing and a Fellow of the International Association for Pattern Recognition (IAPR) for his contributions in pattern recognition, image processing, and for service to IAPR.
Expected output: 'entities: [{'span': 'Haralick', 'entity': 'Researcher'}, {'span': 'IEEE', 'entity': 'Organisation'}, {'span': 'computer vision', 'entity': 'Field'}, {'span': 'image processing', 'entity': 'Field'}, {'span': 'International Association for Pattern Recognition', 'entity': 'Organisation'}, {'span': 'IAPR', 'entity': 'Organisation'}, {'span': 'pattern recognition', 'entity': 'Field'}]'

Example #7: In the middle of the 1990s, while serving as president of the AAAI, Hayes began a series of attacks on critics of AI, mostly phrased in an ironic light, and (together with his colleague Kenneth Ford) invented an award named after Simon Newcomb to be given for the most ridiculous argument disproving the possibility of AI.
Expected output: 'entities: [{'span': 'AAAI', 'entity': 'Conference'}, {'span': 'Hayes', 'entity': 'Researcher'}, {'span': 'AI', 'entity': 'Field'}, {'span': 'Kenneth Ford', 'entity': 'Researcher'}, {'span': 'Simon Newcomb', 'entity': 'Researcher'}]'

Example #8: With long-time collaborator Laurent Cohen, a neurologist at the Pitié-Salpêtrière Hospital in Paris, Dehaene also identified patients with lesions in different regions of the parietal lobe with impaired multiplication, but preserved subtraction (associated with lesions of the inferior parietal lobule) and others with impaired subtraction, but preserved multiplication (associated with lesions to the intraparietal sulcus).
Expected output: 'entities: [{'span': 'Laurent Cohen', 'entity': 'Researcher'}, {'span': 'Pitié-Salpêtrière Hospital', 'entity': 'Organisation'}, {'span': 'Paris', 'entity': 'Location'}, {'span': 'Dehaene', 'entity': 'Researcher'}, {'span': 'parietal lobe', 'entity': 'Misc'}, {'span': 'inferior parietal lobule', 'entity': 'Misc'}, {'span': 'intraparietal sulcus', 'entity': 'Misc'}]'

Example #9: Also in regression analysis, mean squared error, often referred to as mean squared prediction error or out-of-sample mean squared error, can refer to the mean value of the squared deviations of the predictions from the TRUE values, over an out-of-sample test space, generated by a model estimated over a particular sample space.
Expected output: 'entities: [{'span': 'regression analysis', 'entity': 'Task'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'mean squared prediction error', 'entity': 'Metrics'}, {'span': 'out-of-sample mean squared error', 'entity': 'Metrics'}, {'span': 'squared deviations', 'entity': 'Misc'}]'

Example #10: Two of the main methods used in unsupervised learning are principal component analysis and cluster analysis.
Expected output: 'entities: [{'span': 'unsupervised learning', 'entity': 'Field'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'cluster analysis', 'entity': 'Task'}]'

