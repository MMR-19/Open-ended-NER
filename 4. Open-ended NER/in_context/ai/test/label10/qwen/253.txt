Example #1: As with BLEU, the basic unit of evaluation is the sentence, the algorithm first creates an alignment (see illustrations) between two sentence s, the candidate translation string, and the reference translation string.
Expected output: 'entities: [{'span': 'BLEU', 'entity': 'Metrics'}]'

Example #2: tity contains a collection of visualization tools and algorithms for data analysis and predictive modeling, together with graphical user interfaces for easy access to these functions. but the more recent fully Java -based version (Weka 3), for which development started in 1997, is now used in many different application areas, in particular for educational purposes and research.
Expected output: 'entities: [{'span': 'tity', 'entity': 'Product'}, {'span': 'data analysis', 'entity': 'Field'}, {'span': 'predictive modeling', 'entity': 'Task'}, {'span': 'graphical user interfaces', 'entity': 'Misc'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'Weka 3', 'entity': 'Product'}]'

Example #3: If the signal is further ergodic, all sample paths exhibits the same time-average and thus mathR _ x ^ { n / T _ 0 } (\ tau) = \ widehat { R } _ x ^ { n / T _ 0 } (\ tau) / math in mean square error sense.
Expected output: 'entities: [{'span': 'mean square error', 'entity': 'Metrics'}]'

Example #4: One of the metrics used in NIST ' s annual Document Understanding Conferences, in which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.
Expected output: 'entities: [{'span': "NIST ' s annual Document Understanding Conferences", 'entity': 'Conference'}, {'span': 'summarization', 'entity': 'Task'}, {'span': 'translation tasks', 'entity': 'Task'}, {'span': 'ROUGE metric', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}, {'span': 'Neural Information Processing Systems', 'entity': 'Conference'}, {'span': 'NIPS', 'entity': 'Conference'}, {'span': 'Montreal', 'entity': 'Location'}, {'span': 'Canada', 'entity': 'Country'}]'

Example #5: 59, pp. 2547-2553, Oct. 2011 In one dimensional polynomial-based memory (or memoryless) DPD, in order to solve for the digital pre-distorter polynomials coefficients and minimize the mean squared error (MSE), the distorted output of the nonlinear system must be over-sampled at a rate that enables the capture of the nonlinear products of the order of the digital pre-distorter.
Expected output: 'entities: [{'span': 'one dimensional polynomial-based memory', 'entity': 'Misc'}, {'span': 'DPD', 'entity': 'Misc'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #6: With long-time collaborator Laurent Cohen, a neurologist at the Pitié-Salpêtrière Hospital in Paris, Dehaene also identified patients with lesions in different regions of the parietal lobe with impaired multiplication, but preserved subtraction (associated with lesions of the inferior parietal lobule) and others with impaired subtraction, but preserved multiplication (associated with lesions to the intraparietal sulcus).
Expected output: 'entities: [{'span': 'Laurent Cohen', 'entity': 'Researcher'}, {'span': 'Pitié-Salpêtrière Hospital', 'entity': 'Organisation'}, {'span': 'Paris', 'entity': 'Location'}, {'span': 'Dehaene', 'entity': 'Researcher'}, {'span': 'parietal lobe', 'entity': 'Misc'}, {'span': 'inferior parietal lobule', 'entity': 'Misc'}, {'span': 'intraparietal sulcus', 'entity': 'Misc'}]'

Example #7: In the middle of the 1990s, while serving as president of the AAAI, Hayes began a series of attacks on critics of AI, mostly phrased in an ironic light, and (together with his colleague Kenneth Ford) invented an award named after Simon Newcomb to be given for the most ridiculous argument disproving the possibility of AI.
Expected output: 'entities: [{'span': 'AAAI', 'entity': 'Conference'}, {'span': 'Hayes', 'entity': 'Researcher'}, {'span': 'AI', 'entity': 'Field'}, {'span': 'Kenneth Ford', 'entity': 'Researcher'}, {'span': 'Simon Newcomb', 'entity': 'Researcher'}]'

Example #8: Haralick is a Fellow of IEEE for his contributions in computer vision and image processing and a Fellow of the International Association for Pattern Recognition (IAPR) for his contributions in pattern recognition, image processing, and for service to IAPR.
Expected output: 'entities: [{'span': 'Haralick', 'entity': 'Researcher'}, {'span': 'IEEE', 'entity': 'Organisation'}, {'span': 'computer vision', 'entity': 'Field'}, {'span': 'image processing', 'entity': 'Field'}, {'span': 'International Association for Pattern Recognition', 'entity': 'Organisation'}, {'span': 'IAPR', 'entity': 'Organisation'}, {'span': 'pattern recognition', 'entity': 'Field'}]'

Example #9: Linear predictive coding (LPC), a form of speech coding, began development with the work Fumitada Itakura of Nagoya University and Shuzo Saito of Nippon Telegraph and Telephone (NTT) in 1966.
Expected output: 'entities: [{'span': 'Linear predictive coding', 'entity': 'Algorithm'}, {'span': 'LPC', 'entity': 'Algorithm'}, {'span': 'speech coding', 'entity': 'Task'}, {'span': 'Fumitada Itakura', 'entity': 'Researcher'}, {'span': 'Nagoya University', 'entity': 'University'}, {'span': 'Shuzo Saito', 'entity': 'Researcher'}, {'span': 'Nippon Telegraph and Telephone', 'entity': 'University'}, {'span': 'NTT', 'entity': 'University'}]'

Example #10: The NIST metric is based on the BLEU metric, but with some alterations.
Expected output: 'entities: [{'span': 'NIST metric', 'entity': 'Metrics'}, {'span': 'BLEU metric', 'entity': 'Metrics'}]'

