Example #1: One of the metrics used in NIST ' s annual Document Understanding Conferences, in which research groups submit their systems for both summarization and translation tasks, is the ROUGE metric (Recall-Oriented Understudy for Gisting Evaluation, In Advances of Neural Information Processing Systems (NIPS), Montreal, Canada, December - 2014.
Expected output: 'entities: [{'span': "NIST ' s annual Document Understanding Conferences", 'entity': 'Conference'}, {'span': 'summarization', 'entity': 'Task'}, {'span': 'translation tasks', 'entity': 'Task'}, {'span': 'ROUGE metric', 'entity': 'Metrics'}, {'span': 'Recall-Oriented Understudy for Gisting Evaluation', 'entity': 'Metrics'}, {'span': 'Neural Information Processing Systems', 'entity': 'Conference'}, {'span': 'NIPS', 'entity': 'Conference'}, {'span': 'Montreal', 'entity': 'Location'}, {'span': 'Canada', 'entity': 'Country'}]'

Example #2: Feature extraction and dimension reduction can be combined in one step using principal component analysis (PCA), linear discriminant analysis (LDA), canonical correlation analysis (CCA), or non-negative matrix factorization (NMF) techniques as a pre-processing step followed by clustering by K-NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'principal component analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'non-negative matrix factorization', 'entity': 'Algorithm'}, {'span': 'NMF', 'entity': 'Algorithm'}, {'span': 'pre-processing step', 'entity': 'Misc'}, {'span': 'K-NN', 'entity': 'Algorithm'}, {'span': 'feature vectors', 'entity': 'Misc'}]'

Example #3: Feature extraction and dimension reduction can be combined in one step using Principal Component Analysis (PCA), linear discriminant analysis (LDA), or canonical correlation analysis (CCA) techniques as a pre-processing step, followed by clustering by k -NN on feature vectors in reduced-dimension space.
Expected output: 'entities: [{'span': 'Feature extraction', 'entity': 'Task'}, {'span': 'dimension reduction', 'entity': 'Task'}, {'span': 'Principal Component Analysis', 'entity': 'Algorithm'}, {'span': 'PCA', 'entity': 'Algorithm'}, {'span': 'linear discriminant analysis', 'entity': 'Algorithm'}, {'span': 'LDA', 'entity': 'Algorithm'}, {'span': 'canonical correlation analysis', 'entity': 'Algorithm'}, {'span': 'CCA', 'entity': 'Algorithm'}, {'span': 'pre-processing', 'entity': 'Misc'}, {'span': 'k -NN', 'entity': 'Algorithm'}]'

Example #4: Popular approaches of opinion-based recommender system utilize various techniques including text mining, information retrieval, sentiment analysis (see also Multimodal sentiment analysis) and deep learning X.Y. Feng, H. Zhang, Y.J. Ren, P.H. Shang, Y. Zhu, Y.C. Liang, R.C. Guan, D. Xu, (2019),, 21 (5): e12957.
Expected output: 'entities: [{'span': 'opinion-based recommender system', 'entity': 'Product'}, {'span': 'text mining', 'entity': 'Field'}, {'span': 'information retrieval', 'entity': 'Task'}, {'span': 'sentiment analysis', 'entity': 'Task'}, {'span': 'Multimodal sentiment analysis', 'entity': 'Task'}, {'span': 'deep learning', 'entity': 'Field'}, {'span': 'X.Y. Feng', 'entity': 'Researcher'}, {'span': 'H. Zhang', 'entity': 'Researcher'}, {'span': 'Y.J. Ren', 'entity': 'Researcher'}, {'span': 'P.H. Shang', 'entity': 'Researcher'}, {'span': 'Y. Zhu', 'entity': 'Researcher'}, {'span': 'Y.C. Liang', 'entity': 'Researcher'}, {'span': 'R.C. Guan', 'entity': 'Researcher'}, {'span': 'D. Xu', 'entity': 'Researcher'}]'

Example #5: , C. Papageorgiou and T. Poggio, A Trainable Pedestrian Detection system, International Journal of Computer Vision (IJCV), pages 1: 15-33, 2000 others uses local features like histogram of oriented gradients N. Dalal, B. Triggs, Histograms of oriented gradients for human detection, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), pages 1: 886-893, 2005 descriptors.
Expected output: 'entities: [{'span': 'C. Papageorgiou', 'entity': 'Researcher'}, {'span': 'T. Poggio', 'entity': 'Researcher'}, {'span': 'Trainable Pedestrian Detection system', 'entity': 'Product'}, {'span': 'International Journal of Computer Vision', 'entity': 'Conference'}, {'span': 'IJCV', 'entity': 'Conference'}, {'span': 'histogram of oriented gradients', 'entity': 'Algorithm'}, {'span': 'N. Dalal', 'entity': 'Researcher'}, {'span': 'B. Triggs', 'entity': 'Researcher'}, {'span': 'Histograms of oriented gradients', 'entity': 'Algorithm'}, {'span': 'human detection', 'entity': 'Task'}, {'span': 'IEEE Computer Society Conference on Computer Vision and Pattern Recognition', 'entity': 'Conference'}, {'span': 'CVPR', 'entity': 'Conference'}]'

Example #6: tity contains a collection of visualization tools and algorithms for data analysis and predictive modeling, together with graphical user interfaces for easy access to these functions. but the more recent fully Java -based version (Weka 3), for which development started in 1997, is now used in many different application areas, in particular for educational purposes and research.
Expected output: 'entities: [{'span': 'tity', 'entity': 'Product'}, {'span': 'data analysis', 'entity': 'Field'}, {'span': 'predictive modeling', 'entity': 'Task'}, {'span': 'graphical user interfaces', 'entity': 'Misc'}, {'span': 'Java', 'entity': 'Programming Language'}, {'span': 'Weka 3', 'entity': 'Product'}]'

Example #7: 59, pp. 2547-2553, Oct. 2011 In one dimensional polynomial-based memory (or memoryless) DPD, in order to solve for the digital pre-distorter polynomials coefficients and minimize the mean squared error (MSE), the distorted output of the nonlinear system must be over-sampled at a rate that enables the capture of the nonlinear products of the order of the digital pre-distorter.
Expected output: 'entities: [{'span': 'one dimensional polynomial-based memory', 'entity': 'Misc'}, {'span': 'DPD', 'entity': 'Misc'}, {'span': 'mean squared error', 'entity': 'Metrics'}, {'span': 'MSE', 'entity': 'Metrics'}]'

Example #8: In the middle of the 1990s, while serving as president of the AAAI, Hayes began a series of attacks on critics of AI, mostly phrased in an ironic light, and (together with his colleague Kenneth Ford) invented an award named after Simon Newcomb to be given for the most ridiculous argument disproving the possibility of AI.
Expected output: 'entities: [{'span': 'AAAI', 'entity': 'Conference'}, {'span': 'Hayes', 'entity': 'Researcher'}, {'span': 'AI', 'entity': 'Field'}, {'span': 'Kenneth Ford', 'entity': 'Researcher'}, {'span': 'Simon Newcomb', 'entity': 'Researcher'}]'

Example #9: Several of these programs are available online, such as Google Translate and the SYSTRAN system that powers AltaVista's BabelFish (now Yahoo's Babelfish as of 9 May 2008).
Expected output: 'entities: [{'span': 'Google Translate', 'entity': 'Product'}, {'span': 'SYSTRAN system', 'entity': 'Product'}, {'span': 'AltaVista', 'entity': 'Organisation'}, {'span': 'BabelFish', 'entity': 'Product'}, {'span': 'Yahoo', 'entity': 'Organisation'}, {'span': 'Babelfish', 'entity': 'Product'}]'

Example #10: Self-organizing maps differ from other artificial neural networks as they apply competitive learning as opposed to error-correction learning such as backpropagation with gradient descent), and in the sense that they use a neighborhood function to preserve the topological properties of the input space.
Expected output: 'entities: [{'span': 'artificial neural networks', 'entity': 'Algorithm'}, {'span': 'competitive learning', 'entity': 'Algorithm'}, {'span': 'error-correction learning', 'entity': 'Algorithm'}, {'span': 'backpropagation', 'entity': 'Algorithm'}, {'span': 'gradient descent', 'entity': 'Algorithm'}, {'span': 'topological properties', 'entity': 'Misc'}]'

